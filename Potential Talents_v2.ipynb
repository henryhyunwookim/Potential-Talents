{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load import load_data\n",
    "from utils.transform import process_text, TfidfVectorizer\n",
    "from utils.evaluate import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104 entries, 0 to 103\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          104 non-null    int64  \n",
      " 1   job_title   104 non-null    object \n",
      " 2   location    104 non-null    object \n",
      " 3   connection  104 non-null    object \n",
      " 4   fit         0 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 4.2+ KB\n",
      "None \n",
      "\n",
      "               id  fit\n",
      "count  104.000000  0.0\n",
      "mean    52.500000  NaN\n",
      "std     30.166206  NaN\n",
      "min      1.000000  NaN\n",
      "25%     26.750000  NaN\n",
      "50%     52.500000  NaN\n",
      "75%     78.250000  NaN\n",
      "max    104.000000  NaN \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1   2  Native English Teacher at EPIK (English Progra...   \n",
       "2   3              Aspiring Human Resources Professional   \n",
       "3   4             People Development Coordinator at Ryan   \n",
       "4   5    Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \n",
       "0                       Houston, Texas         85  NaN  \n",
       "1                               Kanada      500+   NaN  \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "3                        Denton, Texas      500+   NaN  \n",
       "4                       İzmir, Türkiye      500+   NaN  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data(file_name=\"potential-talents.xlsx\", folder_name=\"data\")\n",
    "print(data.info(), \"\\n\")\n",
    "print(data.describe(), \"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The id column is just an index column that would not be relevant to the fitness of any roles.\n",
    "Although the job_title and location columns are highly correlated, the job_title column seems to be the only relevant column in determining the fitness of a particular role based on the column values and information we have about the requirements.\n",
    "\n",
    "Therefore, only the job_title column will be used in the ranking procedures. Having said that, the other columns will still be returned in the result so that the user (i.e. the client) can have the full information about each of the relevant candidates.\n",
    "The fit column will be filled with a fitness score for each row/candidate later."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get a fitness score (i.e. probability between 0-1) for each candidate based on keywords (\"Aspiring human resources\", \"seeking human resources\").\n",
    "- Only look at the job_title column and ignore the rest because it is unclear whether they are relevant to the fitness of human resources roles that the client is looking to fill.\n",
    "- It can be considered as an Information Retrieval problem where the job title column is a set of documents, the keywords are queries, and the relevance score between each document and queries will become the fitness score for each document.\n",
    "- Transform each job title and keyword into vector representations and compute a cosine similarity (or dot product, or euclidean distance) score for each candidate and use the score as a relevance (or fitness) score.\n",
    "- Can try inverted index for fast search/rank retrieval.\n",
    "- tf-idf, latent semantic indexing can be used.\n",
    "\n",
    "2. Rank candidates according to fitness scores.\n",
    "\n",
    "3. Build a pipeline on top of the above to take user feedback (i.e. 'star') and re-rank candidates based on it.\n",
    "* Taking feedback and returning re-ranked candidates (or just re-ranking candidates) can be in the form of a method/function of a class.\n",
    "\n",
    "4. Additionally, determine a cut-off point to filter out candidates which in the first place should not be on the list. We can take 1) a document selection strategy where a document (i.e. a job_title) is relevant or not based on absolute relevance - it's essentially a binary classification task where 1 is relevant and 0 is not, or 2) a document ranking strategy where there is a cut-off relevance score and documents will be ranked/selected based on relative relevance, which is a regression problem.\n",
    "* This would also work for other roles without losing high potential candidates since the only change in the overall procedures/pipelines will be different job titles and keywords as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the disadvantage of GloVe embedding?\n",
    "One of the main disadvantages of Word2Vec and GloVe embedding is that they are unable to encode unknown or out-of-vocabulary words. So, to deal with this problem Facebook proposed a model FastText. It is an extension to Word2Vec and follows the same Skip-gram and CBOW model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"Aspiring human resources\", \"seeking human resources\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHRO,', 'GPHR', 'SPHR', 'HR', 'HRIS']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title_words = list(set(\" \".join(data['job_title']).split()))\n",
    "hr_words = [word for word in job_title_words if \"HR\" in word]\n",
    "hr_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.transform import convert_terms\n",
    "hr_terms_dict = {'CHRO,': 'Chief Human Resources Officer,',\n",
    "                'GPHR': 'Global Professional in Human Resources',\n",
    "                'SPHR': 'Senior Professional in Human Resources',\n",
    "                'HR': 'Human Resources',\n",
    "                'HRIS': 'Human Resources Information System',\n",
    "                'People': 'Human'} # this is for titles like 'People Development Coordinator at Ryan'.\n",
    "\n",
    "for i, job_title in enumerate(data['job_title']):\n",
    "    converted = []\n",
    "    for word in job_title.split():\n",
    "        converted.append(convert_terms(word, hr_terms_dict))\n",
    "    data.loc[i, 'job_title'] = \" \".join(converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar conversions can be done for terms like \"staff*\", \"employ*\", but we will leave the decision to domain experts and only convert terms that specifically include \"HR\" as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_args = {'strip_accents':'unicode',\n",
    "              'lowercase':True,\n",
    "              'stop_words':'english',\n",
    "              'ngram_range':(1,3)}\n",
    "tfidf_vectorizer = TfidfVectorizer(**tfidf_args)\n",
    "\n",
    "job_title_processed = data['job_title'].apply(\n",
    "    process_text,\n",
    "    remove_stopwords=True,\n",
    "    lemmitize=True,\n",
    "    stem=True\n",
    ")\n",
    "keywords_processed = [process_text(keyword) for keyword in keywords]\n",
    "\n",
    "data['fit_tfidf'] = cosine_similarity(tfidf_vectorizer.fit_transform(job_title_processed),\n",
    "                                      tfidf_vectorizer.transform(keywords_processed)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['job_title'])\n",
    "data['fit_keras_tokenizer'] = cosine_similarity(tokenizer.texts_to_matrix(data['job_title']),\n",
    "                                                tokenizer.texts_to_matrix(keywords)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# glove file source: https://nlp.stanford.edu/projects/glove/\n",
    "# Create temp file and save converted embedding into it\n",
    "target_file = get_tmpfile('word2vec.6B.50d.txt')\n",
    "glove2word2vec('data/glove/glove.6B.50d.txt', target_file)\n",
    "glove_dimension = 50\n",
    "\n",
    "# Load the converted embedding into memory\n",
    "glove_vectors = KeyedVectors.load_word2vec_format(target_file)\n",
    "\n",
    "# Transform keywords into glove vectors\n",
    "glove_vectors_keywords = []\n",
    "for keyword in keywords:\n",
    "    keyword_vector = np.zeros(glove_dimension)\n",
    "    for word in keyword.split():\n",
    "        try:\n",
    "            keyword_vector += glove_vectors[word.lower()]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    glove_vectors_keywords.append(keyword_vector)\n",
    "\n",
    "# Transform job titles into glove vectors\n",
    "glove_vectors_job_title = []\n",
    "for job_title in data['job_title']:\n",
    "    job_title_vector = np.zeros(glove_dimension)\n",
    "    for word in job_title.split():\n",
    "        try:\n",
    "            job_title_vector += glove_vectors[word.lower()]\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    glove_vectors_job_title.append(job_title_vector)\n",
    "\n",
    "# Calculate cosine similarity score between job titles and keywords based on glove vectors and add it to the dataframe.\n",
    "data['fit_glove'] = cosine_similarity(glove_vectors_job_title, glove_vectors_keywords).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec(sentences=data['job_title'].apply(lambda x: [word.lower() for word in x.split()]))\n",
    "word2vec_dimension = word2vec.vector_size\n",
    "\n",
    "# Transform keywords into glove vectors\n",
    "word2vec_keywords = []\n",
    "for keyword in keywords:\n",
    "    keyword_vector = np.zeros(word2vec_dimension)\n",
    "    for word in keyword.split():\n",
    "        try:\n",
    "            keyword_vector += word2vec.wv[word.lower()]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    word2vec_keywords.append(keyword_vector)\n",
    "\n",
    "# Transform job titles into glove vectors\n",
    "word2vec_job_title = []\n",
    "for job_title in data['job_title']:\n",
    "    job_title_vector = np.zeros(word2vec_dimension)\n",
    "    for word in job_title.split():\n",
    "        try:\n",
    "            job_title_vector += word2vec.wv[word.lower()]\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    word2vec_job_title.append(job_title_vector)\n",
    "\n",
    "# Calculate cosine similarity score between job titles and keywords based on glove vectors and add it to the dataframe.\n",
    "data['fit_word2vec'] = cosine_similarity(word2vec_job_title, word2vec_keywords).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "fasttext = FastText(sentences=data['job_title'].apply(lambda x: [word.lower() for word in x.split()]))\n",
    "fasttext_dimension = fasttext.vector_size\n",
    "\n",
    "# Transform keywords into glove vectors\n",
    "fasttext_keywords = []\n",
    "for keyword in keywords:\n",
    "    keyword_vector = np.zeros(fasttext_dimension)\n",
    "    for word in keyword.split():\n",
    "        try:\n",
    "            keyword_vector += fasttext.wv[word.lower()]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    fasttext_keywords.append(keyword_vector)\n",
    "\n",
    "# Transform job titles into glove vectors\n",
    "fasttext_job_title = []\n",
    "for job_title in data['job_title']:\n",
    "    job_title_vector = np.zeros(fasttext_dimension)\n",
    "    for word in job_title.split():\n",
    "        try:\n",
    "            job_title_vector += fasttext.wv[word.lower()]\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    fasttext_job_title.append(job_title_vector)\n",
    "\n",
    "# Calculate cosine similarity score between job titles and keywords based on glove vectors and add it to the dataframe.\n",
    "data['fit_fasttext'] = cosine_similarity(fasttext_job_title, fasttext_keywords).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit_tfidf</th>\n",
       "      <th>fit_keras_tokenizer</th>\n",
       "      <th>fit_glove</th>\n",
       "      <th>fit_word2vec</th>\n",
       "      <th>fit_fasttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.328938</td>\n",
       "      <td>0.511697</td>\n",
       "      <td>0.639963</td>\n",
       "      <td>0.570685</td>\n",
       "      <td>0.516792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.166206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.315271</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.265058</td>\n",
       "      <td>0.311138</td>\n",
       "      <td>0.310942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057644</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.473497</td>\n",
       "      <td>0.299533</td>\n",
       "      <td>0.183819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.253802</td>\n",
       "      <td>0.591047</td>\n",
       "      <td>0.669484</td>\n",
       "      <td>0.674261</td>\n",
       "      <td>0.472658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.497634</td>\n",
       "      <td>0.725639</td>\n",
       "      <td>0.870980</td>\n",
       "      <td>0.839401</td>\n",
       "      <td>0.768933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  fit   fit_tfidf  fit_keras_tokenizer   fit_glove  \\\n",
       "count  104.000000  0.0  104.000000           104.000000  104.000000   \n",
       "mean    52.500000  NaN    0.328938             0.511697    0.639963   \n",
       "std     30.166206  NaN    0.315271             0.349020    0.265058   \n",
       "min      1.000000  NaN    0.000000             0.000000    0.000000   \n",
       "25%     26.750000  NaN    0.057644             0.100000    0.473497   \n",
       "50%     52.500000  NaN    0.253802             0.591047    0.669484   \n",
       "75%     78.250000  NaN    0.497634             0.725639    0.870980   \n",
       "max    104.000000  NaN    1.000000             1.000000    1.000000   \n",
       "\n",
       "       fit_word2vec  fit_fasttext  \n",
       "count    104.000000    104.000000  \n",
       "mean       0.570685      0.516792  \n",
       "std        0.311138      0.310942  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.299533      0.183819  \n",
       "50%        0.674261      0.472658  \n",
       "75%        0.839401      0.768933  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform fit scores so that different fit scores will have the same range between 0 and 1.\n",
    "# This is for easier comparisons among different fit scores.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "fit_columns = [col for col in data.columns if \"fit_\" in col]\n",
    "data[fit_columns] = minmax_scaler.fit_transform(data[fit_columns])\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fit'] = data[fit_columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: job_title, dtype: int64)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['fit']==0].job_title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit_tfidf</th>\n",
       "      <th>fit_keras_tokenizer</th>\n",
       "      <th>fit_glove</th>\n",
       "      <th>fit_word2vec</th>\n",
       "      <th>fit_fasttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>4.882201</td>\n",
       "      <td>0.921024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988652</td>\n",
       "      <td>0.972524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>4.882201</td>\n",
       "      <td>0.921024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988652</td>\n",
       "      <td>0.972524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>4.811019</td>\n",
       "      <td>0.913385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.955780</td>\n",
       "      <td>0.988652</td>\n",
       "      <td>0.953203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.773292</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.924198</td>\n",
       "      <td>0.849094</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.773292</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.924198</td>\n",
       "      <td>0.849094</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                              job_title  \\\n",
       "29  30  Seeking Human Resources Opportunities   \n",
       "27  28  Seeking Human Resources Opportunities   \n",
       "98  99       Seeking Human Resources Position   \n",
       "16  17  Aspiring Human Resources Professional   \n",
       "2    3  Aspiring Human Resources Professional   \n",
       "\n",
       "                               location connection       fit  fit_tfidf  \\\n",
       "29                    Chicago, Illinois        390  4.882201   0.921024   \n",
       "27                    Chicago, Illinois        390  4.882201   0.921024   \n",
       "98               Las Vegas, Nevada Area         48  4.811019   0.913385   \n",
       "16  Raleigh-Durham, North Carolina Area         44  4.773292   1.000000   \n",
       "2   Raleigh-Durham, North Carolina Area         44  4.773292   1.000000   \n",
       "\n",
       "    fit_keras_tokenizer  fit_glove  fit_word2vec  fit_fasttext  \n",
       "29                  1.0   1.000000      0.988652      0.972524  \n",
       "27                  1.0   1.000000      0.988652      0.972524  \n",
       "98                  1.0   0.955780      0.988652      0.953203  \n",
       "16                  1.0   0.924198      0.849094      1.000000  \n",
       "2                   1.0   0.924198      0.849094      1.000000  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values('fit', ascending=False).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the job titles for the candidates who got the highest fitness score, they indeed look very relevant - in fact the job titles include one of the exact keywords \"Aspiring Human Resources\" in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit_tfidf</th>\n",
       "      <th>fit_keras_tokenizer</th>\n",
       "      <th>fit_glove</th>\n",
       "      <th>fit_word2vec</th>\n",
       "      <th>fit_fasttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>0.169533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>0.169533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>0.169533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>0.169533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>RRP Brand Portfolio Executive at JTI (Japan To...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>0.246018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.105107</td>\n",
       "      <td>0.140912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "34  35    Advisory Board Member at Celal Bayar University   \n",
       "47  48    Advisory Board Member at Celal Bayar University   \n",
       "4    5    Advisory Board Member at Celal Bayar University   \n",
       "22  23    Advisory Board Member at Celal Bayar University   \n",
       "84  85  RRP Brand Portfolio Executive at JTI (Japan To...   \n",
       "\n",
       "                     location connection       fit  fit_tfidf  \\\n",
       "34             İzmir, Türkiye      500+   0.169533        0.0   \n",
       "47             İzmir, Türkiye      500+   0.169533        0.0   \n",
       "4              İzmir, Türkiye      500+   0.169533        0.0   \n",
       "22             İzmir, Türkiye      500+   0.169533        0.0   \n",
       "84  Greater Philadelphia Area      500+   0.246018        0.0   \n",
       "\n",
       "    fit_keras_tokenizer  fit_glove  fit_word2vec  fit_fasttext  \n",
       "34                  0.0    0.11365      0.000000      0.055883  \n",
       "47                  0.0    0.11365      0.000000      0.055883  \n",
       "4                   0.0    0.11365      0.000000      0.055883  \n",
       "22                  0.0    0.11365      0.000000      0.055883  \n",
       "84                  0.0    0.00000      0.105107      0.140912  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values('fit', ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['fit']==0].job_title.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit_tfidf</th>\n",
       "      <th>fit_keras_tokenizer</th>\n",
       "      <th>fit_glove</th>\n",
       "      <th>fit_word2vec</th>\n",
       "      <th>fit_fasttext</th>\n",
       "      <th>has_zero_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>2.568075</td>\n",
       "      <td>0.328938</td>\n",
       "      <td>0.511697</td>\n",
       "      <td>0.639963</td>\n",
       "      <td>0.570685</td>\n",
       "      <td>0.516792</td>\n",
       "      <td>0.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.166206</td>\n",
       "      <td>1.472122</td>\n",
       "      <td>0.315271</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.265058</td>\n",
       "      <td>0.311138</td>\n",
       "      <td>0.310942</td>\n",
       "      <td>0.43511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.169533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.750000</td>\n",
       "      <td>1.372012</td>\n",
       "      <td>0.057644</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.473497</td>\n",
       "      <td>0.299533</td>\n",
       "      <td>0.183819</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>2.619778</td>\n",
       "      <td>0.253802</td>\n",
       "      <td>0.591047</td>\n",
       "      <td>0.669484</td>\n",
       "      <td>0.674261</td>\n",
       "      <td>0.472658</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.250000</td>\n",
       "      <td>3.599888</td>\n",
       "      <td>0.497634</td>\n",
       "      <td>0.725639</td>\n",
       "      <td>0.870980</td>\n",
       "      <td>0.839401</td>\n",
       "      <td>0.768933</td>\n",
       "      <td>0.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>4.882201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id         fit   fit_tfidf  fit_keras_tokenizer   fit_glove  \\\n",
       "count  104.000000  104.000000  104.000000           104.000000  104.000000   \n",
       "mean    52.500000    2.568075    0.328938             0.511697    0.639963   \n",
       "std     30.166206    1.472122    0.315271             0.349020    0.265058   \n",
       "min      1.000000    0.169533    0.000000             0.000000    0.000000   \n",
       "25%     26.750000    1.372012    0.057644             0.100000    0.473497   \n",
       "50%     52.500000    2.619778    0.253802             0.591047    0.669484   \n",
       "75%     78.250000    3.599888    0.497634             0.725639    0.870980   \n",
       "max    104.000000    4.882201    1.000000             1.000000    1.000000   \n",
       "\n",
       "       fit_word2vec  fit_fasttext  has_zero_scores  \n",
       "count    104.000000    104.000000        104.00000  \n",
       "mean       0.570685      0.516792          0.25000  \n",
       "std        0.311138      0.310942          0.43511  \n",
       "min        0.000000      0.000000          0.00000  \n",
       "25%        0.299533      0.183819          0.00000  \n",
       "50%        0.674261      0.472658          0.00000  \n",
       "75%        0.839401      0.768933          0.25000  \n",
       "max        1.000000      1.000000          1.00000  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No candidates with a fitness score of 0 although the min fit score of each of the fit_columns is all 0.\n",
    "\n",
    "Add a filter column 'has_zero_scores' for candidates with at least 1 'zero' fitness score from the fit_columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_zero_scores = []\n",
    "for i, row in data.iterrows():\n",
    "    has_zero_score = 0\n",
    "    for fit in data.iloc[i][fit_columns]:\n",
    "        if fit == 0:\n",
    "            has_zero_score = 1\n",
    "    \n",
    "    has_zero_scores.append(has_zero_score)\n",
    "\n",
    "data['has_zero_scores'] = has_zero_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Native English Teacher at EPIK (English Program in Korea)',\n",
       "       'Advisory Board Member at Celal Bayar University',\n",
       "       'Student at Chapman University',\n",
       "       'Junior MES Engineer| Information Systems',\n",
       "       'RRP Brand Portfolio Executive at JTI (Japan Tobacco International)',\n",
       "       'Information Systems Specialist and Programmer with a love for data and organization.',\n",
       "       'Bachelor of Science in Biology from Victoria University of Wellington',\n",
       "       'Undergraduate Research Assistant at Styczynski Lab',\n",
       "       'Lead Official at Western Illinois University',\n",
       "       'Admissions Representative at Community medical center long beach',\n",
       "       'Student at Westfield State University',\n",
       "       'Student at Indiana University Kokomo - Business Management - Retail Manager at Delphi Hardware and Paint',\n",
       "       'Student', 'Business Intelligence and Analytics at Travelers',\n",
       "       'Always set them up for Success',\n",
       "       'Director Of Administration at Excellence Logging'], dtype=object)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['has_zero_scores'] == 1].job_title.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop these values as they indeed seem irrelavant to our keywords, \"Aspiring human resources\" and \"seeking human resources\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_tfidf least fit job title 1: Director Of Administration at Excellence Logging\n",
      "fit_tfidf least fit job title 2: Native English Teacher at EPIK (English Program in Korea)\n",
      "fit_tfidf least fit job title 3: Bachelor of Science in Biology from Victoria University of Wellington\n",
      "fit_tfidf least fit job title 4: Student at Chapman University\n",
      "fit_tfidf least fit job title 5: Advisory Board Member at Celal Bayar University\n",
      "\n",
      "fit_keras_tokenizer least fit job title 1: Director Of Administration at Excellence Logging\n",
      "fit_keras_tokenizer least fit job title 2: Native English Teacher at EPIK (English Program in Korea)\n",
      "fit_keras_tokenizer least fit job title 3: Advisory Board Member at Celal Bayar University\n",
      "fit_keras_tokenizer least fit job title 4: Native English Teacher at EPIK (English Program in Korea)\n",
      "fit_keras_tokenizer least fit job title 5: Advisory Board Member at Celal Bayar University\n",
      "\n",
      "fit_glove least fit job title 1: RRP Brand Portfolio Executive at JTI (Japan Tobacco International)\n",
      "fit_glove least fit job title 2: Student at Chapman University\n",
      "fit_glove least fit job title 3: Student at Chapman University\n",
      "fit_glove least fit job title 4: Student at Chapman University\n",
      "fit_glove least fit job title 5: Student at Chapman University\n",
      "\n",
      "fit_word2vec least fit job title 1: Advisory Board Member at Celal Bayar University\n",
      "fit_word2vec least fit job title 2: Advisory Board Member at Celal Bayar University\n",
      "fit_word2vec least fit job title 3: Advisory Board Member at Celal Bayar University\n",
      "fit_word2vec least fit job title 4: Advisory Board Member at Celal Bayar University\n",
      "fit_word2vec least fit job title 5: Lead Official at Western Illinois University\n",
      "\n",
      "fit_fasttext least fit job title 1: Bachelor of Science in Biology from Victoria University of Wellington\n",
      "fit_fasttext least fit job title 2: Junior MES Engineer| Information Systems\n",
      "fit_fasttext least fit job title 3: Student at Indiana University Kokomo - Business Management - Retail Manager at Delphi Hardware and Paint\n",
      "fit_fasttext least fit job title 4: Advisory Board Member at Celal Bayar University\n",
      "fit_fasttext least fit job title 5: Advisory Board Member at Celal Bayar University\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fit_col in fit_columns:\n",
    "    for i, job_title in enumerate(data.sort_values(fit_col).head().job_title.values):\n",
    "        print(f\"{fit_col} least fit job title {i+1}: {job_title}\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the job titles with the worst fitness scores, each evaluation methods for fitness seems to perform fine - i.e. all those 'worst' job titles do not seem relevant to our keywords."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add rank to each candidate based on fitness scores - set the ranks of all the candidates with a fitness score of 0 to 104 (i.e. data.shape[0]).\n",
    "# train a ranking algorithm (learn to rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. instead of tf-idf, <b>try word2vec or GloVe</b> that can capture nuanced meanings better.\n",
    "2. it not working, one way to do it is replace \"HR\" with \"Human resources\", \"People\" with \"human\" before pre-processing steps.\n",
    "3. once I have good proxy (i.e. similarity score), rank the candidates based on them. and then use a ranking algorithm such as bubble sort or quick sort - we don't feed the algorithm the scores but the rankings and the algorithm will learn how/why they were ranked that way.\n",
    "4. once I have the ranking algorithm, you can take feedback (i.e. manually starred candidates) into the ranking algorithm for re-ranking the candidates based on feedback."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RankNet, LambdaRank, and LambdaMART\n",
    "My first choice would probably by XGBoost, the extreme gradient boosting algorithm. The benefit here (apart from the fact that it’s nearly always brilliant) is that you can set your distance metrics easily to match those of the RankNet, LambdaRank, and LambdaMART models explained above, by passing in the objective parameter in your param dictionary. Here, 'objective: rank:map' corresponds to RankNet, 'objective: rank:ndcg' corresponds to LambdaRank, and 'objective: rank:pairwise' corresponds to LambdaMART.\n",
    "\n",
    "\n",
    "insertion sort, merge sort, and quicksort\n",
    "\n",
    "\n",
    "Learning to rank (LTR) is a method that is used in the construction of classification models for information retrieval systems. The training data consists of lists of articles with an induced partial order that gives a numerical or ordinal score, or a binary judgment for each article. The purpose of the model is to order the elements into new lists according to the scores that take into account the judgments obtained from the articles.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4868653bb6f8972e87e4c446ab8a445a15b25dedb8594cc74c480f8152ea86a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
