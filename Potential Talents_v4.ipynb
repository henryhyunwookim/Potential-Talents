{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load import load_data\n",
    "from utils.split import split_data\n",
    "from utils.process_text import process_text, convert_terms, convert_words_to_vectors, get_word_vectors\n",
    "from utils.predict import get_rank_predictions\n",
    "from utils.evaluate import cosine_similarity\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models.fasttext import FastText\n",
    "from xgboost import XGBRanker\n",
    "from lightgbm import LGBMRanker\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104 entries, 0 to 103\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          104 non-null    int64  \n",
      " 1   job_title   104 non-null    object \n",
      " 2   location    104 non-null    object \n",
      " 3   connection  104 non-null    object \n",
      " 4   fit         0 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 4.2+ KB\n",
      "None \n",
      "\n",
      "               id  fit\n",
      "count  104.000000  0.0\n",
      "mean    52.500000  NaN\n",
      "std     30.166206  NaN\n",
      "min      1.000000  NaN\n",
      "25%     26.750000  NaN\n",
      "50%     52.500000  NaN\n",
      "75%     78.250000  NaN\n",
      "max    104.000000  NaN \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1   2  Native English Teacher at EPIK (English Progra...   \n",
       "2   3              Aspiring Human Resources Professional   \n",
       "3   4             People Development Coordinator at Ryan   \n",
       "4   5    Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \n",
       "0                       Houston, Texas         85  NaN  \n",
       "1                               Kanada      500+   NaN  \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "3                        Denton, Texas      500+   NaN  \n",
       "4                       İzmir, Türkiye      500+   NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data(file_name=\"potential-talents.xlsx\", folder_name=\"data\")\n",
    "print(data.info(), \"\\n\")\n",
    "print(data.describe(), \"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProfileReport(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The id column is just an index column that would not be relevant to the fitness of any roles.\n",
    "Although the job_title and location columns are highly correlated, the job_title column seems to be the only relevant column in determining the fitness of a particular role based on the column values and information we have about the requirements.\n",
    "\n",
    "Therefore, only the job_title column will be used in the ranking procedures. Having said that, the other columns will still be returned in the result so that the user (i.e. the client) can have the full information about each of the relevant candidates.\n",
    "The fit column will be filled with a fitness score for each row/candidate later."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pre-process job titles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert human resources-related terms in a way that job titles containing those terms will have better fitness scores. That is, those job titles might end up having a fitness score of 0 without conversion because for instance \"HR\" and \"Human Resources\" would be considered to have nothing in common by most algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHRO,', 'HR', 'HRIS', 'GPHR', 'SPHR']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title_words = list(set(\" \".join(data['job_title']).split()))\n",
    "hr_words = [word for word in job_title_words if \"HR\" in word]\n",
    "hr_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_terms_dict = {'CHRO,': 'Chief Human Resources Officer,',\n",
    "                'GPHR': 'Global Professional in Human Resources',\n",
    "                'SPHR': 'Senior Professional in Human Resources',\n",
    "                'HR': 'Human Resources',\n",
    "                'HRIS': 'Human Resources Information System',\n",
    "                'People': 'Human'} # this is for titles like 'People Development Coordinator at Ryan'.\n",
    "\n",
    "for i, job_title in enumerate(data['job_title']):\n",
    "    converted = []\n",
    "    for word in job_title.split():\n",
    "        converted.append(convert_terms(word, hr_terms_dict))\n",
    "    data.loc[i, 'job_title'] = \" \".join(converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar conversions can be done for terms like \"staff*\", \"employ*\", but we will leave the decision to domain experts and only convert terms that specifically include \"HR\" as above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get fitness scores\n",
    "based on cosine similary between job titles and keywords using different algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some descriptions about tfidf to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_args = {'strip_accents':'unicode',\n",
    "              'lowercase':True,\n",
    "              'stop_words':'english',\n",
    "              'ngram_range':(1,3)}\n",
    "tfidf_vectorizer = TfidfVectorizer(**tfidf_args)\n",
    "\n",
    "job_title_processed_tfidf = data['job_title'].apply(\n",
    "    process_text,\n",
    "    remove_stopwords=True,\n",
    "    lemmatize=True,\n",
    "    stem=True\n",
    ")\n",
    "\n",
    "keywords = [\"Aspiring human resources\", \"seeking human resources\"]\n",
    "keywords_processed_tfidf = [process_text(keyword) for keyword in keywords]\n",
    "\n",
    "data['fit_tfidf'] = cosine_similarity(tfidf_vectorizer.fit_transform(job_title_processed_tfidf),\n",
    "                                      tfidf_vectorizer.transform(keywords_processed_tfidf)).sum(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For other vectorizers, only remove stopwords without lemmatization or stemming since stopwords do not add any values/meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_processed = data['job_title'].apply(\n",
    "    process_text,\n",
    "    remove_stopwords=True,\n",
    "    lemmatize=False,\n",
    "    stem=False\n",
    ")\n",
    "keywords_processed = [process_text(\n",
    "    keyword,\n",
    "    remove_stopwords=True,\n",
    "    lemmatize=False,\n",
    "    stem=False\n",
    "    ) for keyword in keywords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some descriptions about tensorflow.keras Tokenizer to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(job_title_processed) # fit_on_texts updates internal vocabulary based on a list of texts; similar to tf-idf.\n",
    "data['fit_keras_tokenizer'] = cosine_similarity(tokenizer.texts_to_matrix(job_title_processed),\n",
    "                                                tokenizer.texts_to_matrix(keywords_processed)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some descriptions about gensim, glove, and word2vec to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove file source: https://nlp.stanford.edu/projects/glove/\n",
    "word2vec_file = get_tmpfile('word2vec.6B.50d.txt') # Create a temp file\n",
    "glove2word2vec('data/glove/glove.6B.50d.txt', word2vec_file) # Save glove2word2vec into the temp file\n",
    "glove_vectors = KeyedVectors.load_word2vec_format(word2vec_file) # Load the glove2word2vec from the teamp file\n",
    "glove_dimension = 50\n",
    "\n",
    "# Transform job titles and keywords into glove vectors\n",
    "glove_vectors_job_title = convert_words_to_vectors(job_title_processed, glove_vectors, glove_dimension)\n",
    "glove_vectors_keywords = convert_words_to_vectors(keywords_processed, glove_vectors, glove_dimension)\n",
    "data['fit_glove'] = cosine_similarity(glove_vectors_job_title, glove_vectors_keywords).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(sentences=job_title_processed.apply(lambda x: [word.lower() for word in x.split()]))\n",
    "word2vec_dimension = word2vec.vector_size\n",
    "\n",
    "# Transform job titles and keywords into word2vec vectors\n",
    "word2vec_job_title = convert_words_to_vectors(job_title_processed, word2vec, word2vec_dimension)\n",
    "word2vec_keywords = convert_words_to_vectors(keywords_processed, word2vec, word2vec_dimension)\n",
    "data['fit_word2vec'] = cosine_similarity(word2vec_job_title, word2vec_keywords).sum(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the disadvantage of GloVe embedding?\n",
    "One of the main disadvantages of Word2Vec and GloVe embedding is that they are unable to encode unknown or out-of-vocabulary words. So, to deal with this problem Facebook proposed a model FastText. It is an extension to Word2Vec and follows the same Skip-gram and CBOW model.\n",
    "\n",
    "some descriptions about fasttext to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext = FastText(sentences=job_title_processed.apply(lambda x: [word.lower() for word in x.split()]))\n",
    "fasttext_dimension = fasttext.vector_size\n",
    "\n",
    "# Transform job titles and keywords into fasttext vectors\n",
    "fasttext_job_title = convert_words_to_vectors(job_title_processed, fasttext, fasttext_dimension)\n",
    "fasttext_keywords = convert_words_to_vectors(keywords_processed, fasttext, fasttext_dimension)\n",
    "data['fit_fasttext'] = cosine_similarity(fasttext_job_title, fasttext_keywords).sum(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform fit scores so that different fit scores will have the same range between 0 and 1.<br>\n",
    "This is for easier comparisons among different fit scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit_tfidf</th>\n",
       "      <th>fit_keras_tokenizer</th>\n",
       "      <th>fit_glove</th>\n",
       "      <th>fit_word2vec</th>\n",
       "      <th>fit_fasttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.328938</td>\n",
       "      <td>0.541808</td>\n",
       "      <td>0.604935</td>\n",
       "      <td>0.628118</td>\n",
       "      <td>0.586781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.166206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.315271</td>\n",
       "      <td>0.359278</td>\n",
       "      <td>0.313345</td>\n",
       "      <td>0.321920</td>\n",
       "      <td>0.290476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057644</td>\n",
       "      <td>0.106066</td>\n",
       "      <td>0.286359</td>\n",
       "      <td>0.404847</td>\n",
       "      <td>0.422400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.253802</td>\n",
       "      <td>0.642826</td>\n",
       "      <td>0.664575</td>\n",
       "      <td>0.747274</td>\n",
       "      <td>0.684321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.497634</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.864163</td>\n",
       "      <td>0.868069</td>\n",
       "      <td>0.776623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  fit   fit_tfidf  fit_keras_tokenizer   fit_glove  \\\n",
       "count  104.000000  0.0  104.000000           104.000000  104.000000   \n",
       "mean    52.500000  NaN    0.328938             0.541808    0.604935   \n",
       "std     30.166206  NaN    0.315271             0.359278    0.313345   \n",
       "min      1.000000  NaN    0.000000             0.000000    0.000000   \n",
       "25%     26.750000  NaN    0.057644             0.106066    0.286359   \n",
       "50%     52.500000  NaN    0.253802             0.642826    0.664575   \n",
       "75%     78.250000  NaN    0.497634             0.800000    0.864163   \n",
       "max    104.000000  NaN    1.000000             1.000000    1.000000   \n",
       "\n",
       "       fit_word2vec  fit_fasttext  \n",
       "count    104.000000    104.000000  \n",
       "mean       0.628118      0.586781  \n",
       "std        0.321920      0.290476  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.404847      0.422400  \n",
       "50%        0.747274      0.684321  \n",
       "75%        0.868069      0.776623  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_scaler = MinMaxScaler()\n",
    "fit_columns = [col for col in data.columns if \"fit_\" in col]\n",
    "data[fit_columns] = minmax_scaler.fit_transform(data[fit_columns])\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fit'] = data[fit_columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: job_title, dtype: int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['fit']==0].job_title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit_tfidf</th>\n",
       "      <th>fit_keras_tokenizer</th>\n",
       "      <th>fit_glove</th>\n",
       "      <th>fit_word2vec</th>\n",
       "      <th>fit_fasttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>4.818086</td>\n",
       "      <td>0.921024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963193</td>\n",
       "      <td>0.933869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>4.818086</td>\n",
       "      <td>0.921024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963193</td>\n",
       "      <td>0.933869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>4.752442</td>\n",
       "      <td>0.913385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.953443</td>\n",
       "      <td>0.963193</td>\n",
       "      <td>0.922421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.745850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.868069</td>\n",
       "      <td>0.957589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.745850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.868069</td>\n",
       "      <td>0.957589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                              job_title  \\\n",
       "27  28  Seeking Human Resources Opportunities   \n",
       "29  30  Seeking Human Resources Opportunities   \n",
       "98  99       Seeking Human Resources Position   \n",
       "32  33  Aspiring Human Resources Professional   \n",
       "2    3  Aspiring Human Resources Professional   \n",
       "\n",
       "                               location connection       fit  fit_tfidf  \\\n",
       "27                    Chicago, Illinois        390  4.818086   0.921024   \n",
       "29                    Chicago, Illinois        390  4.818086   0.921024   \n",
       "98               Las Vegas, Nevada Area         48  4.752442   0.913385   \n",
       "32  Raleigh-Durham, North Carolina Area         44  4.745850   1.000000   \n",
       "2   Raleigh-Durham, North Carolina Area         44  4.745850   1.000000   \n",
       "\n",
       "    fit_keras_tokenizer  fit_glove  fit_word2vec  fit_fasttext  \n",
       "27                  1.0   1.000000      0.963193      0.933869  \n",
       "29                  1.0   1.000000      0.963193      0.933869  \n",
       "98                  1.0   0.953443      0.963193      0.922421  \n",
       "32                  1.0   0.920193      0.868069      0.957589  \n",
       "2                   1.0   0.920193      0.868069      0.957589  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values('fit', ascending=False).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the job titles for the candidates who got the highest fitness score, they indeed look very relevant - in fact the job titles include one of the exact keywords \"Aspiring Human Resources\" in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit_tfidf</th>\n",
       "      <th>fit_keras_tokenizer</th>\n",
       "      <th>fit_glove</th>\n",
       "      <th>fit_word2vec</th>\n",
       "      <th>fit_fasttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>0.169637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>0.169637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>0.169637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>0.169637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87</td>\n",
       "      <td>Bachelor of Science in Biology from Victoria U...</td>\n",
       "      <td>Baltimore, Maryland</td>\n",
       "      <td>40</td>\n",
       "      <td>0.175027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "34  35    Advisory Board Member at Celal Bayar University   \n",
       "47  48    Advisory Board Member at Celal Bayar University   \n",
       "4    5    Advisory Board Member at Celal Bayar University   \n",
       "22  23    Advisory Board Member at Celal Bayar University   \n",
       "86  87  Bachelor of Science in Biology from Victoria U...   \n",
       "\n",
       "               location connection       fit  fit_tfidf  fit_keras_tokenizer  \\\n",
       "34       İzmir, Türkiye      500+   0.169637        0.0                  0.0   \n",
       "47       İzmir, Türkiye      500+   0.169637        0.0                  0.0   \n",
       "4        İzmir, Türkiye      500+   0.169637        0.0                  0.0   \n",
       "22       İzmir, Türkiye      500+   0.169637        0.0                  0.0   \n",
       "86  Baltimore, Maryland         40  0.175027        0.0                  0.0   \n",
       "\n",
       "    fit_glove  fit_word2vec  fit_fasttext  \n",
       "34    0.00000           0.0      0.169637  \n",
       "47    0.00000           0.0      0.169637  \n",
       "4     0.00000           0.0      0.169637  \n",
       "22    0.00000           0.0      0.169637  \n",
       "86    0.05825           0.0      0.116777  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values('fit', ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['fit']==0].job_title.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit_tfidf</th>\n",
       "      <th>fit_keras_tokenizer</th>\n",
       "      <th>fit_glove</th>\n",
       "      <th>fit_word2vec</th>\n",
       "      <th>fit_fasttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>2.690579</td>\n",
       "      <td>0.328938</td>\n",
       "      <td>0.541808</td>\n",
       "      <td>0.604935</td>\n",
       "      <td>0.628118</td>\n",
       "      <td>0.586781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.166206</td>\n",
       "      <td>1.488648</td>\n",
       "      <td>0.315271</td>\n",
       "      <td>0.359278</td>\n",
       "      <td>0.313345</td>\n",
       "      <td>0.321920</td>\n",
       "      <td>0.290476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.169637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.750000</td>\n",
       "      <td>1.543442</td>\n",
       "      <td>0.057644</td>\n",
       "      <td>0.106066</td>\n",
       "      <td>0.286359</td>\n",
       "      <td>0.404847</td>\n",
       "      <td>0.422400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>2.997542</td>\n",
       "      <td>0.253802</td>\n",
       "      <td>0.642826</td>\n",
       "      <td>0.664575</td>\n",
       "      <td>0.747274</td>\n",
       "      <td>0.684321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.250000</td>\n",
       "      <td>3.559670</td>\n",
       "      <td>0.497634</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.864163</td>\n",
       "      <td>0.868069</td>\n",
       "      <td>0.776623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>4.818086</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id         fit   fit_tfidf  fit_keras_tokenizer   fit_glove  \\\n",
       "count  104.000000  104.000000  104.000000           104.000000  104.000000   \n",
       "mean    52.500000    2.690579    0.328938             0.541808    0.604935   \n",
       "std     30.166206    1.488648    0.315271             0.359278    0.313345   \n",
       "min      1.000000    0.169637    0.000000             0.000000    0.000000   \n",
       "25%     26.750000    1.543442    0.057644             0.106066    0.286359   \n",
       "50%     52.500000    2.997542    0.253802             0.642826    0.664575   \n",
       "75%     78.250000    3.559670    0.497634             0.800000    0.864163   \n",
       "max    104.000000    4.818086    1.000000             1.000000    1.000000   \n",
       "\n",
       "       fit_word2vec  fit_fasttext  \n",
       "count    104.000000    104.000000  \n",
       "mean       0.628118      0.586781  \n",
       "std        0.321920      0.290476  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.404847      0.422400  \n",
       "50%        0.747274      0.684321  \n",
       "75%        0.868069      0.776623  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No candidates with a fitness score of 0 although the min fit score of each of the fit_columns is all 0.\n",
    "\n",
    "Add a filter column 'has_zero_scores' for candidates with at least 1 'zero' fitness score from the fit_columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_zero_scores = []\n",
    "for i, row in data.iterrows():\n",
    "    has_zero_score = 0\n",
    "    for fit in data.iloc[i][fit_columns]:\n",
    "        if fit == 0:\n",
    "            has_zero_score = 1\n",
    "    \n",
    "    has_zero_scores.append(has_zero_score)\n",
    "\n",
    "data['has_zero_scores'] = has_zero_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Native English Teacher at EPIK (English Program in Korea)',\n",
       "       'Advisory Board Member at Celal Bayar University',\n",
       "       'Student at Chapman University',\n",
       "       'Junior MES Engineer| Information Systems',\n",
       "       'RRP Brand Portfolio Executive at JTI (Japan Tobacco International)',\n",
       "       'Information Systems Specialist and Programmer with a love for data and organization.',\n",
       "       'Bachelor of Science in Biology from Victoria University of Wellington',\n",
       "       'Undergraduate Research Assistant at Styczynski Lab',\n",
       "       'Lead Official at Western Illinois University',\n",
       "       'Admissions Representative at Community medical center long beach',\n",
       "       'Student at Westfield State University',\n",
       "       'Student at Indiana University Kokomo - Business Management - Retail Manager at Delphi Hardware and Paint',\n",
       "       'Student', 'Business Intelligence and Analytics at Travelers',\n",
       "       'Always set them up for Success',\n",
       "       'Director Of Administration at Excellence Logging'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['has_zero_scores'] == 1].job_title.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop these values as they indeed seem irrelavant to our keywords, \"Aspiring human resources\" and \"seeking human resources\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_tfidf least fit job title 1: Director Of Administration at Excellence Logging\n",
      "fit_tfidf least fit job title 2: Native English Teacher at EPIK (English Program in Korea)\n",
      "fit_tfidf least fit job title 3: Bachelor of Science in Biology from Victoria University of Wellington\n",
      "fit_tfidf least fit job title 4: Student at Chapman University\n",
      "fit_tfidf least fit job title 5: Advisory Board Member at Celal Bayar University\n",
      "\n",
      "fit_keras_tokenizer least fit job title 1: Director Of Administration at Excellence Logging\n",
      "fit_keras_tokenizer least fit job title 2: Native English Teacher at EPIK (English Program in Korea)\n",
      "fit_keras_tokenizer least fit job title 3: Advisory Board Member at Celal Bayar University\n",
      "fit_keras_tokenizer least fit job title 4: Native English Teacher at EPIK (English Program in Korea)\n",
      "fit_keras_tokenizer least fit job title 5: Advisory Board Member at Celal Bayar University\n",
      "\n",
      "fit_glove least fit job title 1: Advisory Board Member at Celal Bayar University\n",
      "fit_glove least fit job title 2: Advisory Board Member at Celal Bayar University\n",
      "fit_glove least fit job title 3: Advisory Board Member at Celal Bayar University\n",
      "fit_glove least fit job title 4: Advisory Board Member at Celal Bayar University\n",
      "fit_glove least fit job title 5: Student at Chapman University\n",
      "\n",
      "fit_word2vec least fit job title 1: Advisory Board Member at Celal Bayar University\n",
      "fit_word2vec least fit job title 2: Advisory Board Member at Celal Bayar University\n",
      "fit_word2vec least fit job title 3: Advisory Board Member at Celal Bayar University\n",
      "fit_word2vec least fit job title 4: Advisory Board Member at Celal Bayar University\n",
      "fit_word2vec least fit job title 5: Lead Official at Western Illinois University\n",
      "\n",
      "fit_fasttext least fit job title 1: Student at Westfield State University\n",
      "fit_fasttext least fit job title 2: Always set them up for Success\n",
      "fit_fasttext least fit job title 3: Director Of Administration at Excellence Logging\n",
      "fit_fasttext least fit job title 4: Junior MES Engineer| Information Systems\n",
      "fit_fasttext least fit job title 5: Business Intelligence and Analytics at Travelers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fit_col in fit_columns:\n",
    "    for i, job_title in enumerate(data.sort_values(fit_col).head().job_title.values):\n",
    "        print(f\"{fit_col} least fit job title {i+1}: {job_title}\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the job titles with the worst fitness scores, each evaluation methods for fitness seems to perform fine - i.e. all those 'worst' job titles do not seem relevant to our keywords. In other words, it would be safe to discard candidates with zero fitness scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = data[ data['has_zero_scores'] != 1 ].drop('has_zero_scores', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are top 20 'best-fit' candidates and their job titles, after dropping candidates with at least 1 zero fitness scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique job titles of top 20 candidates:\n",
      "['Seeking Human Resources Opportunities'\n",
      " 'Seeking Human Resources Position'\n",
      " 'Aspiring Human Resources Professional'\n",
      " 'Aspiring Human Resources Manager, seeking internship in Human Resources.'\n",
      " 'Aspiring Human Resources Specialist'\n",
      " 'Seeking Human Resources Human Resources Information System and Generalist Positions']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit_tfidf</th>\n",
       "      <th>fit_keras_tokenizer</th>\n",
       "      <th>fit_glove</th>\n",
       "      <th>fit_word2vec</th>\n",
       "      <th>fit_fasttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>4.818086</td>\n",
       "      <td>0.921024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963193</td>\n",
       "      <td>0.933869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>4.818086</td>\n",
       "      <td>0.921024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963193</td>\n",
       "      <td>0.933869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>4.752442</td>\n",
       "      <td>0.913385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953443</td>\n",
       "      <td>0.963193</td>\n",
       "      <td>0.922421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.745850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.868069</td>\n",
       "      <td>0.957589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.745850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.868069</td>\n",
       "      <td>0.957589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.745850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.868069</td>\n",
       "      <td>0.957589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.745850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.868069</td>\n",
       "      <td>0.957589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.745850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.868069</td>\n",
       "      <td>0.957589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.745850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.868069</td>\n",
       "      <td>0.957589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>97</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Kokomo, Indiana Area</td>\n",
       "      <td>71</td>\n",
       "      <td>4.745850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.868069</td>\n",
       "      <td>0.957589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>73</td>\n",
       "      <td>Aspiring Human Resources Manager, seeking inte...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>7</td>\n",
       "      <td>4.609975</td>\n",
       "      <td>0.648168</td>\n",
       "      <td>0.979796</td>\n",
       "      <td>0.982011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>4.563534</td>\n",
       "      <td>0.830646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962413</td>\n",
       "      <td>0.857085</td>\n",
       "      <td>0.913391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>24</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>4.563534</td>\n",
       "      <td>0.830646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962413</td>\n",
       "      <td>0.857085</td>\n",
       "      <td>0.913391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>4.563534</td>\n",
       "      <td>0.830646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962413</td>\n",
       "      <td>0.857085</td>\n",
       "      <td>0.913391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>49</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>4.563534</td>\n",
       "      <td>0.830646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962413</td>\n",
       "      <td>0.857085</td>\n",
       "      <td>0.913391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>4.563534</td>\n",
       "      <td>0.830646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962413</td>\n",
       "      <td>0.857085</td>\n",
       "      <td>0.913391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>Seeking Human Resources Human Resources Inform...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>4.268874</td>\n",
       "      <td>0.736714</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.953667</td>\n",
       "      <td>0.912245</td>\n",
       "      <td>0.910319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40</td>\n",
       "      <td>Seeking Human Resources Human Resources Inform...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>4.268874</td>\n",
       "      <td>0.736714</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.953667</td>\n",
       "      <td>0.912245</td>\n",
       "      <td>0.910319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>53</td>\n",
       "      <td>Seeking Human Resources Human Resources Inform...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>4.268874</td>\n",
       "      <td>0.736714</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.953667</td>\n",
       "      <td>0.912245</td>\n",
       "      <td>0.910319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>62</td>\n",
       "      <td>Seeking Human Resources Human Resources Inform...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>4.268874</td>\n",
       "      <td>0.736714</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.953667</td>\n",
       "      <td>0.912245</td>\n",
       "      <td>0.910319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "0   28              Seeking Human Resources Opportunities   \n",
       "1   30              Seeking Human Resources Opportunities   \n",
       "2   99                   Seeking Human Resources Position   \n",
       "3    3              Aspiring Human Resources Professional   \n",
       "4   17              Aspiring Human Resources Professional   \n",
       "5   21              Aspiring Human Resources Professional   \n",
       "6   33              Aspiring Human Resources Professional   \n",
       "7   46              Aspiring Human Resources Professional   \n",
       "8   58              Aspiring Human Resources Professional   \n",
       "9   97              Aspiring Human Resources Professional   \n",
       "10  73  Aspiring Human Resources Manager, seeking inte...   \n",
       "11   6                Aspiring Human Resources Specialist   \n",
       "12  24                Aspiring Human Resources Specialist   \n",
       "13  36                Aspiring Human Resources Specialist   \n",
       "14  49                Aspiring Human Resources Specialist   \n",
       "15  60                Aspiring Human Resources Specialist   \n",
       "16  10  Seeking Human Resources Human Resources Inform...   \n",
       "17  40  Seeking Human Resources Human Resources Inform...   \n",
       "18  53  Seeking Human Resources Human Resources Inform...   \n",
       "19  62  Seeking Human Resources Human Resources Inform...   \n",
       "\n",
       "                               location connection       fit  fit_tfidf  \\\n",
       "0                     Chicago, Illinois        390  4.818086   0.921024   \n",
       "1                     Chicago, Illinois        390  4.818086   0.921024   \n",
       "2                Las Vegas, Nevada Area         48  4.752442   0.913385   \n",
       "3   Raleigh-Durham, North Carolina Area         44  4.745850   1.000000   \n",
       "4   Raleigh-Durham, North Carolina Area         44  4.745850   1.000000   \n",
       "5   Raleigh-Durham, North Carolina Area         44  4.745850   1.000000   \n",
       "6   Raleigh-Durham, North Carolina Area         44  4.745850   1.000000   \n",
       "7   Raleigh-Durham, North Carolina Area         44  4.745850   1.000000   \n",
       "8   Raleigh-Durham, North Carolina Area         44  4.745850   1.000000   \n",
       "9                  Kokomo, Indiana Area         71  4.745850   1.000000   \n",
       "10                  Houston, Texas Area          7  4.609975   0.648168   \n",
       "11           Greater New York City Area          1  4.563534   0.830646   \n",
       "12           Greater New York City Area          1  4.563534   0.830646   \n",
       "13           Greater New York City Area          1  4.563534   0.830646   \n",
       "14           Greater New York City Area          1  4.563534   0.830646   \n",
       "15           Greater New York City Area          1  4.563534   0.830646   \n",
       "16            Greater Philadelphia Area      500+   4.268874   0.736714   \n",
       "17            Greater Philadelphia Area      500+   4.268874   0.736714   \n",
       "18            Greater Philadelphia Area      500+   4.268874   0.736714   \n",
       "19            Greater Philadelphia Area      500+   4.268874   0.736714   \n",
       "\n",
       "    fit_keras_tokenizer  fit_glove  fit_word2vec  fit_fasttext  \n",
       "0              1.000000   1.000000      0.963193      0.933869  \n",
       "1              1.000000   1.000000      0.963193      0.933869  \n",
       "2              1.000000   0.953443      0.963193      0.922421  \n",
       "3              1.000000   0.920193      0.868069      0.957589  \n",
       "4              1.000000   0.920193      0.868069      0.957589  \n",
       "5              1.000000   0.920193      0.868069      0.957589  \n",
       "6              1.000000   0.920193      0.868069      0.957589  \n",
       "7              1.000000   0.920193      0.868069      0.957589  \n",
       "8              1.000000   0.920193      0.868069      0.957589  \n",
       "9              1.000000   0.920193      0.868069      0.957589  \n",
       "10             0.979796   0.982011      1.000000      1.000000  \n",
       "11             1.000000   0.962413      0.857085      0.913391  \n",
       "12             1.000000   0.962413      0.857085      0.913391  \n",
       "13             1.000000   0.962413      0.857085      0.913391  \n",
       "14             1.000000   0.962413      0.857085      0.913391  \n",
       "15             1.000000   0.962413      0.857085      0.913391  \n",
       "16             0.755929   0.953667      0.912245      0.910319  \n",
       "17             0.755929   0.953667      0.912245      0.910319  \n",
       "18             0.755929   0.953667      0.912245      0.910319  \n",
       "19             0.755929   0.953667      0.912245      0.910319  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered = data_filtered.sort_values(['fit', 'id', 'connection'], ascending=[False, True, True]).reset_index(drop=True)\n",
    "print(f\"Unique job titles of top 20 candidates:\\n{data_filtered.head(20).job_title.unique()}\")\n",
    "data_filtered.head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train ranking models - XGBoost and LGBM Rankers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize job titles using fasttext and use the word vectors as training features.<br>\n",
    "The rank of each candidate will be the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = pd.DataFrame(\n",
    "    get_word_vectors(data_filtered, 'job_title', vectorizer='fasttext',\n",
    "                     to_process_text=True, remove_stopwords=True, lemmatize=False, stem=False)\n",
    ")\n",
    "data_selected = pd.concat([data_filtered, training_features], axis=1)\n",
    "X = data_selected[training_features.columns]\n",
    "y = data_selected['fit']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test sets before train any model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "random_state = 1\n",
    "X_train, X_test, y_train_fitness, y_test_fitness = split_data(\n",
    "    X, y, test_size, random_state=random_state, oversampling=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert fitness scores into ranks for y_train and y_test separately so that each data set has ranks starting from 1 to the number of data points. Also change the name of the series (or column) from 'fit' to 'rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train_fitness.rank(method='dense', ascending=False)\n",
    "y_train.name = 'rank'\n",
    "\n",
    "y_test = y_test_fitness.rank(method='dense', ascending=False)\n",
    "y_test.name = 'rank'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Train an XGBoost Ranker, and get prediction results.\n",
    "\n",
    "descriptions about XGBoost to be added.\n",
    "* Evaluation metric: NDCG (normalized discounted cumulative gain) is a measure of the effectiveness of a ranking system, taking into account the position of relevant items in the ranked list. It is based on the idea that items that are higher in the ranking should be given more credit than items that are lower in the ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rank of top 5 candidates based on predictions: 2.7368\n",
      "Mean rank of all candidates based on predictions: 12.0484\n",
      "Std rank of all candidates based on predictions: 9.8371\n",
      "   rank  pred_rank\n",
      "3   2.0        1.0\n",
      "8   2.0        1.0\n",
      "7   2.0        1.0\n",
      "4   2.0        1.0\n",
      "6   2.0        1.0 \n",
      "\n",
      "Mean rank of top 5 candidates based on predictions: 3.25\n",
      "Mean rank of all candidates based on predictions: 5.625\n",
      "Std rank of all candidates based on predictions: 3.4809\n",
      "    rank  pred_rank\n",
      "2    1.0        1.0\n",
      "34   4.0        2.0\n",
      "38   4.0        2.0\n",
      "33   4.0        2.0\n",
      "36   4.0        2.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'n_estimators': 40,\n",
    "    # 'max_depth': 2,\n",
    "    'learning_rate': 0.02, # same as xgb's eta; default=0.3\n",
    "    'objective': 'rank:pairwise', # perform better than 'rank:ndcg'\n",
    "    'booster': 'gbtree',\n",
    "    'eval_metric': 'ndcg',\n",
    "    # 'subsample': 0.5,\n",
    "    'gamma': 4.5, # default=0; the larger the more conservative\n",
    "    # 'min_child_weight': 2, # default=1; the larger the more conservative\n",
    "    'random_state': random_state\n",
    "}\n",
    "\n",
    "xgb_ranker = XGBRanker(**xgb_params)\n",
    "xgb_ranker.fit(X_train, y_train,\n",
    "               group=y_train.value_counts(),\n",
    "               eval_set=[(X_test, y_test)],\n",
    "               eval_group=[y_test.value_counts()]\n",
    "               )\n",
    "\n",
    "xgb_train_result = get_rank_predictions(X_train, y_train, xgb_ranker, target_column=\"rank\", target=\"candidates\")\n",
    "xgb_test_result = get_rank_predictions(X_test, y_test, xgb_ranker, target_column=\"rank\", target=\"candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (Top 5 rankers):  2.7368 3.375\n",
      "Mean:  15.0161 6.125\n",
      "Std:  10.4685 3.2838\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean (Top 5 rankers): \", round(y_train[y_train<=5].mean(), 4), round(y_test[y_test<=5].mean(), 4))\n",
    "print(\"Mean: \", round(y_train.mean(), 4), round(y_test.mean(), 4))\n",
    "print(\"Std: \", round(y_train.std(), 4), round(y_test.std(), 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Train an LGBM (Light Gradient-Boosting Machine) Ranker, and get prediction results.\n",
    "\n",
    "descriptions about LGBM to be added.\n",
    "* Ranking algorithm: LambdaRank. This is a technique where ranking is transformed into a pairwise classification or regression problem. Basically, the algorithms consider a pair of items at a single time to come up with a viable ordering of those items before initiating the final order of the entire list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rank of top 5 candidates based on predictions: 2.7895\n",
      "Mean rank of all candidates based on predictions: 14.5806\n",
      "Std rank of all candidates based on predictions: 10.5653\n",
      "   rank  pred_rank\n",
      "3   2.0        1.0\n",
      "8   2.0        1.0\n",
      "7   2.0        1.0\n",
      "4   2.0        1.0\n",
      "6   2.0        1.0 \n",
      "\n",
      "Mean rank of top 5 candidates based on predictions: 3.25\n",
      "Mean rank of all candidates based on predictions: 6.0\n",
      "Std rank of all candidates based on predictions: 3.4833\n",
      "    rank  pred_rank\n",
      "2    1.0        1.0\n",
      "10   2.0        2.0\n",
      "34   4.0        3.0\n",
      "38   4.0        3.0\n",
      "33   4.0        3.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm_ranker = LGBMRanker(\n",
    "    boosting=\"dart\", # 'dbdt', 'dart', 'rf',\n",
    "    # max_depth=2,\n",
    "    objective=\"lambdarank\",\n",
    "    metric= \"ndcg\",\n",
    "    label_gain =[i for i in range(int(max(y_train.max(), y_test.max())) + 1)],\n",
    "    random_state=random_state\n",
    "    )\n",
    "\n",
    "lgbm_ranker.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    group=y_train.value_counts(),\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_group=[y_test.value_counts()],\n",
    "    # eval_at=[1,3,5]\n",
    "    verbose=-1\n",
    "    )\n",
    "\n",
    "_ = get_rank_predictions(X_train, y_train, lgbm_ranker, target_column=\"rank\", target=\"candidates\")\n",
    "_ = get_rank_predictions(X_test, y_test, lgbm_ranker, target_column=\"rank\", target=\"candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (Top 5 rankers):  2.7368 3.375\n",
      "Mean:  15.0161 6.125\n",
      "Std:  10.4685 3.2838\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean (Top 5 rankers): \", round(y_train[y_train<=5].mean(), 4), round(y_test[y_test<=5].mean(), 4))\n",
    "print(\"Mean: \", round(y_train.mean(), 4), round(y_test.mean(), 4))\n",
    "print(\"Std: \", round(y_train.std(), 4), round(y_test.std(), 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both rankers successfully predicted the top-ranked candidates (i.e. pred_rank == 1.0) as they all were selected candidates.\n",
    "\n",
    "In terms of the mean of predicted ranks for selected candidates, the LGBM ranker performed better at predicting selected candidates. Therefore, the model will be used instead of the XGB ranker for the rest of the project.\n",
    "\n",
    "* Overall, the predictions by the LGBM ranker were quite close to the ground truths without much hyperparameter tuning, even though some hyperparameter tuning was done for the XGB ranker."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Star ideal candidates and re-train the ranking model based on the updated ranks/criteria.\n",
    "\n",
    "Since we've built our base ranking model, proceed to starring ideal candidates and re-rank all candidates based on the stars.\n",
    "* Starring one candidate sets this candidate as an ideal candidate for the given role. Then, we re-rank the list each time a candidate or a list of candidates is starred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These candidates are not found: [2, 5]\n",
      "Ideal candidates found: [4, 55]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit_tfidf</th>\n",
       "      <th>fit_keras_tokenizer</th>\n",
       "      <th>fit_glove</th>\n",
       "      <th>fit_word2vec</th>\n",
       "      <th>fit_fasttext</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>55</td>\n",
       "      <td>SVP, Chief Human Resources Officer, Marketing ...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>2.908451</td>\n",
       "      <td>0.253802</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.806559</td>\n",
       "      <td>0.763770</td>\n",
       "      <td>0.684321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>-0.001572</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>-0.002574</td>\n",
       "      <td>0.004562</td>\n",
       "      <td>0.010534</td>\n",
       "      <td>0.004009</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>-0.005587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4</td>\n",
       "      <td>Human Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>1.919834</td>\n",
       "      <td>0.076859</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.581306</td>\n",
       "      <td>0.310457</td>\n",
       "      <td>0.551213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00049</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>-0.005985</td>\n",
       "      <td>-0.002965</td>\n",
       "      <td>-0.002307</td>\n",
       "      <td>-0.003458</td>\n",
       "      <td>-0.004558</td>\n",
       "      <td>-0.001452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "53  55  SVP, Chief Human Resources Officer, Marketing ...   \n",
       "71   4              Human Development Coordinator at Ryan   \n",
       "\n",
       "               location connection       fit  fit_tfidf  fit_keras_tokenizer  \\\n",
       "53  Houston, Texas Area      500+   2.908451   0.253802                  0.4   \n",
       "71        Denton, Texas      500+   1.919834   0.076859                  0.4   \n",
       "\n",
       "    fit_glove  fit_word2vec  fit_fasttext  ...       90        91        92  \\\n",
       "53   0.806559      0.763770      0.684321  ...  0.00150  0.002279 -0.001572   \n",
       "71   0.581306      0.310457      0.551213  ...  0.00049  0.000080  0.000380   \n",
       "\n",
       "          93        94        95        96        97        98        99  \n",
       "53  0.001481 -0.002574  0.004562  0.010534  0.004009  0.005654 -0.005587  \n",
       "71  0.002786 -0.005985 -0.002965 -0.002307 -0.003458 -0.004558 -0.001452  \n",
       "\n",
       "[2 rows x 112 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_ids = sorted(data_selected.id.unique())\n",
    "input_ids = input(f\"\"\"\n",
    "Enter IDs of ideal candidates, separated by comma:\n",
    "* IDs: {unique_ids}\n",
    "\"\"\")\n",
    "\n",
    "ideal_candidates = [int(id.strip()) for id in input_ids.split(',')]\n",
    "candidates_not_found = sorted([id for id in ideal_candidates if id not in unique_ids])\n",
    "print(f\"These candidates are not found: {candidates_not_found}\")\n",
    "\n",
    "ideal_candidates_df = data_selected[data_selected['id'].isin(ideal_candidates)].sort_values(['rank', 'id', 'connection'])\n",
    "print(f\"Ideal candidates found: {sorted(list(ideal_candidates_df['id'].values))}\")\n",
    "ideal_candidates_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the 'selected?' column values to True for those starred candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selected.loc[ideal_candidates_df.index, 'selected?'] = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then reassign y and repeat the modeling processes from train-test-split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# need to manually split data? ideal candidates should be in the training data, otherwise the 'feedback' will not be taken into account in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.88268\tvalid_0's ndcg@5: 0.893851\n",
      "[2]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.88268\tvalid_0's ndcg@5: 0.893851\n",
      "[3]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.851959\tvalid_0's ndcg@5: 0.868295\n",
      "[4]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.851959\tvalid_0's ndcg@5: 0.868295\n",
      "[5]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[6]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.851959\tvalid_0's ndcg@5: 0.868295\n",
      "[7]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.851959\tvalid_0's ndcg@5: 0.792785\n",
      "[8]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[9]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.851959\tvalid_0's ndcg@5: 0.868295\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.851959\tvalid_0's ndcg@5: 0.868295\n",
      "[11]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.851959\tvalid_0's ndcg@5: 0.868295\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[15]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[16]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[17]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[18]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[19]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[20]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[21]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[22]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[23]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[24]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[25]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[26]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[27]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[28]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[29]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[31]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[32]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.854764\n",
      "[33]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[34]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[35]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[36]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[37]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[38]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[39]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[40]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[41]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[42]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[43]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[44]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[45]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[46]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[47]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[48]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[49]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[50]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[51]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[52]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[53]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[54]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[55]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[56]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[57]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[58]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[59]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[60]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[61]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[62]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[63]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[64]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[65]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[66]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[67]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[68]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[69]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[70]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[71]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[72]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.779254\n",
      "[73]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[74]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[75]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[76]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[77]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[78]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[79]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[80]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[81]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[82]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[83]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[84]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[85]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[86]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[87]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[88]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[89]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[90]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[91]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[92]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[93]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[94]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[95]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[96]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[97]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[98]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[99]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n",
      "[100]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.734639\tvalid_0's ndcg@5: 0.7707\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRanker(label_gain=[0, 1], metric=&#x27;ndcg&#x27;, objective=&#x27;lambdarank&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRanker</label><div class=\"sk-toggleable__content\"><pre>LGBMRanker(label_gain=[0, 1], metric=&#x27;ndcg&#x27;, objective=&#x27;lambdarank&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRanker(label_gain=[0, 1], metric='ndcg', objective='lambdarank')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data_selected['selected']\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    X, y, test_size, stratify=data_selected['selected'], random_state=random_state, oversampling=False)\n",
    "\n",
    "lgbm_ranker.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    group=y_train.value_counts(),\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_group=[y_test.value_counts()],\n",
    "    eval_at=[1,3,5]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rank of selected candidates based on predictions: 2.7647\n",
      "   selected?  pred_rank\n",
      "8       True        1.0\n",
      "5       True        1.0\n",
      "2       True        1.0\n",
      "4       True        1.0\n",
      "3       True        1.0 \n",
      "\n",
      "Mean rank of selected candidates based on predictions: 5.2\n",
      "    selected?  pred_rank\n",
      "12       True        1.0\n",
      "13       True        1.0\n",
      "56      False        2.0\n",
      "27      False        3.0\n",
      "28      False        4.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = get_rank_predictions(X_train, y_train, lgbm_ranker, target=\"candidates\")\n",
    "_ = get_rank_predictions(X_test, y_test, lgbm_ranker, target=\"candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rank of selected candidates based on predictions: 2.7647\n",
      "   selected?  pred_rank\n",
      "8       True        1.0\n",
      "5       True        1.0\n",
      "2       True        1.0\n",
      "4       True        1.0\n",
      "3       True        1.0 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected?</th>\n",
       "      <th>pred_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>False</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>True</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>False</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>False</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>False</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>False</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>False</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>False</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>False</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>False</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>False</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>False</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>False</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>False</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>False</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>False</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    selected?  pred_rank\n",
       "8        True        1.0\n",
       "5        True        1.0\n",
       "2        True        1.0\n",
       "4        True        1.0\n",
       "3        True        1.0\n",
       "6        True        1.0\n",
       "7        True        1.0\n",
       "15       True        2.0\n",
       "14       True        2.0\n",
       "11       True        2.0\n",
       "1        True        3.0\n",
       "0        True        3.0\n",
       "10       True        4.0\n",
       "54      False        5.0\n",
       "52      False        5.0\n",
       "53       True        5.0\n",
       "51       True        5.0\n",
       "73      False        6.0\n",
       "74      False        6.0\n",
       "72      False        6.0\n",
       "75      False        6.0\n",
       "76       True        6.0\n",
       "47      False        7.0\n",
       "70      False        8.0\n",
       "67      False        8.0\n",
       "65      False        8.0\n",
       "66      False        8.0\n",
       "68      False        8.0\n",
       "69      False        8.0\n",
       "64       True        8.0\n",
       "48      False        9.0\n",
       "23      False       10.0\n",
       "22      False       11.0\n",
       "30      False       12.0\n",
       "49      False       13.0\n",
       "59      False       14.0\n",
       "18      False       15.0\n",
       "19      False       15.0\n",
       "45      False       16.0\n",
       "46      False       17.0\n",
       "50      False       18.0\n",
       "77      False       19.0\n",
       "61      False       20.0\n",
       "63      False       20.0\n",
       "60      False       20.0\n",
       "55      False       21.0\n",
       "20      False       22.0\n",
       "35      False       23.0\n",
       "33      False       23.0\n",
       "34      False       23.0\n",
       "37      False       24.0\n",
       "42      False       25.0\n",
       "41      False       25.0\n",
       "44      False       25.0\n",
       "40      False       25.0\n",
       "38      False       25.0\n",
       "39      False       25.0\n",
       "43      False       25.0\n",
       "26      False       26.0\n",
       "58      False       27.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = get_rank_predictions(X_train, y_train, lgbm_ranker, target=\"candidates\")\n",
    "train.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_filtered['fit_adjusted'] = data_filtered['fit']\n",
    "\n",
    "# ideal_candidate = input(\"Enter an ID of an ideal candidate: \")\n",
    "# data_filtered.loc[int(ideal_candidate), 'fit_adjusted'] = 5\n",
    "\n",
    "# data_filtered['rank_adjusted'] = data_filtered['fit_adjusted'].rank(method='dense', ascending=False)\n",
    "# data_filtered.sort_values(['rank_adjusted', 'rank', 'fit_adjusted', 'fit', 'id', 'connection'], inplace=True)\n",
    "# data_filtered.head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- after starring and re-ranking, re-train the model and see how the model performs.\n",
    "- save and load the model for re-training model and making predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4868653bb6f8972e87e4c446ab8a445a15b25dedb8594cc74c480f8152ea86a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
