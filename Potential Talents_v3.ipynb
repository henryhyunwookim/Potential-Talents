{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load import load_data\n",
    "from utils.split import split_data\n",
    "from utils.process_text import process_text, convert_terms, convert_words_to_vectors, get_word_vectors\n",
    "from utils.predict import get_rank_predictions\n",
    "from utils.evaluate import cosine_similarity\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models.fasttext import FastText"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104 entries, 0 to 103\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          104 non-null    int64  \n",
      " 1   job_title   104 non-null    object \n",
      " 2   location    104 non-null    object \n",
      " 3   connection  104 non-null    object \n",
      " 4   fit         0 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 4.2+ KB\n",
      "None \n",
      "\n",
      "               id  fit\n",
      "count  104.000000  0.0\n",
      "mean    52.500000  NaN\n",
      "std     30.166206  NaN\n",
      "min      1.000000  NaN\n",
      "25%     26.750000  NaN\n",
      "50%     52.500000  NaN\n",
      "75%     78.250000  NaN\n",
      "max    104.000000  NaN \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1   2  Native English Teacher at EPIK (English Progra...   \n",
       "2   3              Aspiring Human Resources Professional   \n",
       "3   4             People Development Coordinator at Ryan   \n",
       "4   5    Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \n",
       "0                       Houston, Texas         85  NaN  \n",
       "1                               Kanada      500+   NaN  \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "3                        Denton, Texas      500+   NaN  \n",
       "4                       İzmir, Türkiye      500+   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data(file_name=\"potential-talents.xlsx\", folder_name=\"data\")\n",
    "print(data.info(), \"\\n\")\n",
    "print(data.describe(), \"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProfileReport(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The id column is just an index column that would not be relevant to the fitness of any roles.\n",
    "Although the job_title and location columns are highly correlated, the job_title column seems to be the only relevant column in determining the fitness of a particular role based on the column values and information we have about the requirements.\n",
    "\n",
    "Therefore, only the job_title column will be used in the ranking procedures. Having said that, the other columns will still be returned in the result so that the user (i.e. the client) can have the full information about each of the relevant candidates.\n",
    "The fit column will be filled with a fitness score for each row/candidate later."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pre-process job titles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert human resources-related terms in a way that job titles containing those terms will have better fitness scores. That is, those job titles might end up having a fitness score of 0 without conversion because for instance \"HR\" and \"Human Resources\" would be considered to have nothing in common by most algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HRIS', 'GPHR', 'SPHR', 'CHRO,', 'HR']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title_words = list(set(\" \".join(data['job_title']).split()))\n",
    "hr_words = [word for word in job_title_words if \"HR\" in word]\n",
    "hr_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_terms_dict = {'CHRO,': 'Chief Human Resources Officer,',\n",
    "                'GPHR': 'Global Professional in Human Resources',\n",
    "                'SPHR': 'Senior Professional in Human Resources',\n",
    "                'HR': 'Human Resources',\n",
    "                'HRIS': 'Human Resources Information System',\n",
    "                'People': 'Human'} # this is for titles like 'People Development Coordinator at Ryan'.\n",
    "\n",
    "for i, job_title in enumerate(data['job_title']):\n",
    "    converted = []\n",
    "    for word in job_title.split():\n",
    "        converted.append(convert_terms(word, hr_terms_dict))\n",
    "    data.loc[i, 'job_title'] = \" \".join(converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar conversions can be done for terms like \"staff*\", \"employ*\", but we will leave the decision to domain experts and only convert terms that specifically include \"HR\" as above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get fitness scores\n",
    "based on cosine similary between job titles and keywords using different algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some descriptions about tfidf to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_args = {'strip_accents':'unicode',\n",
    "              'lowercase':True,\n",
    "              'stop_words':'english',\n",
    "              'ngram_range':(1,3)}\n",
    "tfidf_vectorizer = TfidfVectorizer(**tfidf_args)\n",
    "\n",
    "job_title_processed_tfidf = data['job_title'].apply(\n",
    "    process_text,\n",
    "    remove_stopwords=True,\n",
    "    lemmatize=True,\n",
    "    stem=True\n",
    ")\n",
    "\n",
    "keywords = [\"Aspiring human resources\", \"seeking human resources\"]\n",
    "keywords_processed_tfidf = [process_text(keyword) for keyword in keywords]\n",
    "\n",
    "data['fit_tfidf'] = cosine_similarity(tfidf_vectorizer.fit_transform(job_title_processed_tfidf),\n",
    "                                      tfidf_vectorizer.transform(keywords_processed_tfidf)).sum(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For other vectorizers, only remove stopwords without lemmatization or stemming since stopwords do not add any values/meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_processed = data['job_title'].apply(\n",
    "    process_text,\n",
    "    remove_stopwords=True,\n",
    "    lemmatize=False,\n",
    "    stem=False\n",
    ")\n",
    "keywords_processed = [process_text(\n",
    "    keyword,\n",
    "    remove_stopwords=True,\n",
    "    lemmatize=False,\n",
    "    stem=False\n",
    "    ) for keyword in keywords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some descriptions about tensorflow.keras Tokenizer to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(job_title_processed) # fit_on_texts updates internal vocabulary based on a list of texts; similar to tf-idf.\n",
    "data['fit_keras_tokenizer'] = cosine_similarity(tokenizer.texts_to_matrix(job_title_processed),\n",
    "                                                tokenizer.texts_to_matrix(keywords_processed)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some descriptions about gensim, glove, and word2vec to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove file source: https://nlp.stanford.edu/projects/glove/\n",
    "word2vec_file = get_tmpfile('word2vec.6B.50d.txt') # Create a temp file\n",
    "glove2word2vec('data/glove/glove.6B.50d.txt', word2vec_file) # Save glove2word2vec into the temp file\n",
    "glove_vectors = KeyedVectors.load_word2vec_format(word2vec_file) # Load the glove2word2vec from the teamp file\n",
    "glove_dimension = 50\n",
    "\n",
    "# Transform job titles and keywords into glove vectors\n",
    "glove_vectors_job_title = convert_words_to_vectors(job_title_processed, glove_vectors, glove_dimension)\n",
    "glove_vectors_keywords = convert_words_to_vectors(keywords_processed, glove_vectors, glove_dimension)\n",
    "data['fit_glove'] = cosine_similarity(glove_vectors_job_title, glove_vectors_keywords).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(sentences=job_title_processed.apply(lambda x: [word.lower() for word in x.split()]))\n",
    "word2vec_dimension = word2vec.vector_size\n",
    "\n",
    "# Transform job titles and keywords into word2vec vectors\n",
    "word2vec_job_title = convert_words_to_vectors(job_title_processed, word2vec, word2vec_dimension)\n",
    "word2vec_keywords = convert_words_to_vectors(keywords_processed, word2vec, word2vec_dimension)\n",
    "data['fit_word2vec'] = cosine_similarity(word2vec_job_title, word2vec_keywords).sum(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the disadvantage of GloVe embedding?\n",
    "One of the main disadvantages of Word2Vec and GloVe embedding is that they are unable to encode unknown or out-of-vocabulary words. So, to deal with this problem Facebook proposed a model FastText. It is an extension to Word2Vec and follows the same Skip-gram and CBOW model.\n",
    "\n",
    "some descriptions about fasttext to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext = FastText(sentences=job_title_processed.apply(lambda x: [word.lower() for word in x.split()]))\n",
    "fasttext_dimension = fasttext.vector_size\n",
    "\n",
    "# Transform job titles and keywords into fasttext vectors\n",
    "fasttext_job_title = convert_words_to_vectors(job_title_processed, fasttext, fasttext_dimension)\n",
    "fasttext_keywords = convert_words_to_vectors(keywords_processed, fasttext, fasttext_dimension)\n",
    "data['fit_fasttext'] = cosine_similarity(fasttext_job_title, fasttext_keywords).sum(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform fit scores so that different fit scores will have the same range between 0 and 1.<br>\n",
    "This is for easier comparisons among different fit scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit_tfidf</th>\n",
       "      <th>fit_keras_tokenizer</th>\n",
       "      <th>fit_glove</th>\n",
       "      <th>fit_word2vec</th>\n",
       "      <th>fit_fasttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.328938</td>\n",
       "      <td>0.541808</td>\n",
       "      <td>0.604935</td>\n",
       "      <td>0.586916</td>\n",
       "      <td>0.586781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.166206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.315271</td>\n",
       "      <td>0.359278</td>\n",
       "      <td>0.313345</td>\n",
       "      <td>0.330465</td>\n",
       "      <td>0.290476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057644</td>\n",
       "      <td>0.106066</td>\n",
       "      <td>0.286359</td>\n",
       "      <td>0.271869</td>\n",
       "      <td>0.422400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.253802</td>\n",
       "      <td>0.642826</td>\n",
       "      <td>0.664575</td>\n",
       "      <td>0.723198</td>\n",
       "      <td>0.684321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.497634</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.864163</td>\n",
       "      <td>0.851907</td>\n",
       "      <td>0.776623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  fit   fit_tfidf  fit_keras_tokenizer   fit_glove  \\\n",
       "count  104.000000  0.0  104.000000           104.000000  104.000000   \n",
       "mean    52.500000  NaN    0.328938             0.541808    0.604935   \n",
       "std     30.166206  NaN    0.315271             0.359278    0.313345   \n",
       "min      1.000000  NaN    0.000000             0.000000    0.000000   \n",
       "25%     26.750000  NaN    0.057644             0.106066    0.286359   \n",
       "50%     52.500000  NaN    0.253802             0.642826    0.664575   \n",
       "75%     78.250000  NaN    0.497634             0.800000    0.864163   \n",
       "max    104.000000  NaN    1.000000             1.000000    1.000000   \n",
       "\n",
       "       fit_word2vec  fit_fasttext  \n",
       "count    104.000000    104.000000  \n",
       "mean       0.586916      0.586781  \n",
       "std        0.330465      0.290476  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.271869      0.422400  \n",
       "50%        0.723198      0.684321  \n",
       "75%        0.851907      0.776623  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "fit_columns = [col for col in data.columns if \"fit_\" in col]\n",
    "data[fit_columns] = minmax_scaler.fit_transform(data[fit_columns])\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fit'] = data[fit_columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: job_title, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['fit']==0].job_title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit_tfidf</th>\n",
       "      <th>fit_keras_tokenizer</th>\n",
       "      <th>fit_glove</th>\n",
       "      <th>fit_word2vec</th>\n",
       "      <th>fit_fasttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>4.831050</td>\n",
       "      <td>0.921024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976156</td>\n",
       "      <td>0.933869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>4.831050</td>\n",
       "      <td>0.921024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976156</td>\n",
       "      <td>0.933869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>4.765405</td>\n",
       "      <td>0.913385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.953443</td>\n",
       "      <td>0.976156</td>\n",
       "      <td>0.922421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.729689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.851907</td>\n",
       "      <td>0.957589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.729689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.851907</td>\n",
       "      <td>0.957589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                              job_title  \\\n",
       "27  28  Seeking Human Resources Opportunities   \n",
       "29  30  Seeking Human Resources Opportunities   \n",
       "98  99       Seeking Human Resources Position   \n",
       "32  33  Aspiring Human Resources Professional   \n",
       "2    3  Aspiring Human Resources Professional   \n",
       "\n",
       "                               location connection       fit  fit_tfidf  \\\n",
       "27                    Chicago, Illinois        390  4.831050   0.921024   \n",
       "29                    Chicago, Illinois        390  4.831050   0.921024   \n",
       "98               Las Vegas, Nevada Area         48  4.765405   0.913385   \n",
       "32  Raleigh-Durham, North Carolina Area         44  4.729689   1.000000   \n",
       "2   Raleigh-Durham, North Carolina Area         44  4.729689   1.000000   \n",
       "\n",
       "    fit_keras_tokenizer  fit_glove  fit_word2vec  fit_fasttext  \n",
       "27                  1.0   1.000000      0.976156      0.933869  \n",
       "29                  1.0   1.000000      0.976156      0.933869  \n",
       "98                  1.0   0.953443      0.976156      0.922421  \n",
       "32                  1.0   0.920193      0.851907      0.957589  \n",
       "2                   1.0   0.920193      0.851907      0.957589  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values('fit', ascending=False).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the job titles for the candidates who got the highest fitness score, they indeed look very relevant - in fact the job titles include one of the exact keywords \"Aspiring Human Resources\" in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit_tfidf</th>\n",
       "      <th>fit_keras_tokenizer</th>\n",
       "      <th>fit_glove</th>\n",
       "      <th>fit_word2vec</th>\n",
       "      <th>fit_fasttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>0.206994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.037357</td>\n",
       "      <td>0.169637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>0.206994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.037357</td>\n",
       "      <td>0.169637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>0.206994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.037357</td>\n",
       "      <td>0.169637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>0.206994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.037357</td>\n",
       "      <td>0.169637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87</td>\n",
       "      <td>Bachelor of Science in Biology from Victoria U...</td>\n",
       "      <td>Baltimore, Maryland</td>\n",
       "      <td>40</td>\n",
       "      <td>0.212384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05825</td>\n",
       "      <td>0.037357</td>\n",
       "      <td>0.116777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "34  35    Advisory Board Member at Celal Bayar University   \n",
       "47  48    Advisory Board Member at Celal Bayar University   \n",
       "4    5    Advisory Board Member at Celal Bayar University   \n",
       "22  23    Advisory Board Member at Celal Bayar University   \n",
       "86  87  Bachelor of Science in Biology from Victoria U...   \n",
       "\n",
       "               location connection       fit  fit_tfidf  fit_keras_tokenizer  \\\n",
       "34       İzmir, Türkiye      500+   0.206994        0.0                  0.0   \n",
       "47       İzmir, Türkiye      500+   0.206994        0.0                  0.0   \n",
       "4        İzmir, Türkiye      500+   0.206994        0.0                  0.0   \n",
       "22       İzmir, Türkiye      500+   0.206994        0.0                  0.0   \n",
       "86  Baltimore, Maryland         40  0.212384        0.0                  0.0   \n",
       "\n",
       "    fit_glove  fit_word2vec  fit_fasttext  \n",
       "34    0.00000      0.037357      0.169637  \n",
       "47    0.00000      0.037357      0.169637  \n",
       "4     0.00000      0.037357      0.169637  \n",
       "22    0.00000      0.037357      0.169637  \n",
       "86    0.05825      0.037357      0.116777  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values('fit', ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['fit']==0].job_title.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit_tfidf</th>\n",
       "      <th>fit_keras_tokenizer</th>\n",
       "      <th>fit_glove</th>\n",
       "      <th>fit_word2vec</th>\n",
       "      <th>fit_fasttext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>2.649377</td>\n",
       "      <td>0.328938</td>\n",
       "      <td>0.541808</td>\n",
       "      <td>0.604935</td>\n",
       "      <td>0.586916</td>\n",
       "      <td>0.586781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.166206</td>\n",
       "      <td>1.499756</td>\n",
       "      <td>0.315271</td>\n",
       "      <td>0.359278</td>\n",
       "      <td>0.313345</td>\n",
       "      <td>0.330465</td>\n",
       "      <td>0.290476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.750000</td>\n",
       "      <td>1.561719</td>\n",
       "      <td>0.057644</td>\n",
       "      <td>0.106066</td>\n",
       "      <td>0.286359</td>\n",
       "      <td>0.271869</td>\n",
       "      <td>0.422400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>2.894279</td>\n",
       "      <td>0.253802</td>\n",
       "      <td>0.642826</td>\n",
       "      <td>0.664575</td>\n",
       "      <td>0.723198</td>\n",
       "      <td>0.684321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.250000</td>\n",
       "      <td>3.534292</td>\n",
       "      <td>0.497634</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.864163</td>\n",
       "      <td>0.851907</td>\n",
       "      <td>0.776623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>4.831050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id         fit   fit_tfidf  fit_keras_tokenizer   fit_glove  \\\n",
       "count  104.000000  104.000000  104.000000           104.000000  104.000000   \n",
       "mean    52.500000    2.649377    0.328938             0.541808    0.604935   \n",
       "std     30.166206    1.499756    0.315271             0.359278    0.313345   \n",
       "min      1.000000    0.206994    0.000000             0.000000    0.000000   \n",
       "25%     26.750000    1.561719    0.057644             0.106066    0.286359   \n",
       "50%     52.500000    2.894279    0.253802             0.642826    0.664575   \n",
       "75%     78.250000    3.534292    0.497634             0.800000    0.864163   \n",
       "max    104.000000    4.831050    1.000000             1.000000    1.000000   \n",
       "\n",
       "       fit_word2vec  fit_fasttext  \n",
       "count    104.000000    104.000000  \n",
       "mean       0.586916      0.586781  \n",
       "std        0.330465      0.290476  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.271869      0.422400  \n",
       "50%        0.723198      0.684321  \n",
       "75%        0.851907      0.776623  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No candidates with a fitness score of 0 although the min fit score of each of the fit_columns is all 0.\n",
    "\n",
    "Add a filter column 'has_zero_scores' for candidates with at least 1 'zero' fitness score from the fit_columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_zero_scores = []\n",
    "for i, row in data.iterrows():\n",
    "    has_zero_score = 0\n",
    "    for fit in data.iloc[i][fit_columns]:\n",
    "        if fit == 0:\n",
    "            has_zero_score = 1\n",
    "    \n",
    "    has_zero_scores.append(has_zero_score)\n",
    "\n",
    "data['has_zero_scores'] = has_zero_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Native English Teacher at EPIK (English Program in Korea)',\n",
       "       'Advisory Board Member at Celal Bayar University',\n",
       "       'Student at Chapman University',\n",
       "       'Junior MES Engineer| Information Systems',\n",
       "       'RRP Brand Portfolio Executive at JTI (Japan Tobacco International)',\n",
       "       'Information Systems Specialist and Programmer with a love for data and organization.',\n",
       "       'Bachelor of Science in Biology from Victoria University of Wellington',\n",
       "       'Undergraduate Research Assistant at Styczynski Lab',\n",
       "       'Lead Official at Western Illinois University',\n",
       "       'Admissions Representative at Community medical center long beach',\n",
       "       'Student at Westfield State University',\n",
       "       'Student at Indiana University Kokomo - Business Management - Retail Manager at Delphi Hardware and Paint',\n",
       "       'Student', 'Business Intelligence and Analytics at Travelers',\n",
       "       'Always set them up for Success',\n",
       "       'Director Of Administration at Excellence Logging'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['has_zero_scores'] == 1].job_title.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop these values as they indeed seem irrelavant to our keywords, \"Aspiring human resources\" and \"seeking human resources\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_tfidf least fit job title 1: Director Of Administration at Excellence Logging\n",
      "fit_tfidf least fit job title 2: Native English Teacher at EPIK (English Program in Korea)\n",
      "fit_tfidf least fit job title 3: Bachelor of Science in Biology from Victoria University of Wellington\n",
      "fit_tfidf least fit job title 4: Student at Chapman University\n",
      "fit_tfidf least fit job title 5: Advisory Board Member at Celal Bayar University\n",
      "\n",
      "fit_keras_tokenizer least fit job title 1: Director Of Administration at Excellence Logging\n",
      "fit_keras_tokenizer least fit job title 2: Native English Teacher at EPIK (English Program in Korea)\n",
      "fit_keras_tokenizer least fit job title 3: Advisory Board Member at Celal Bayar University\n",
      "fit_keras_tokenizer least fit job title 4: Native English Teacher at EPIK (English Program in Korea)\n",
      "fit_keras_tokenizer least fit job title 5: Advisory Board Member at Celal Bayar University\n",
      "\n",
      "fit_glove least fit job title 1: Advisory Board Member at Celal Bayar University\n",
      "fit_glove least fit job title 2: Advisory Board Member at Celal Bayar University\n",
      "fit_glove least fit job title 3: Advisory Board Member at Celal Bayar University\n",
      "fit_glove least fit job title 4: Advisory Board Member at Celal Bayar University\n",
      "fit_glove least fit job title 5: Student at Chapman University\n",
      "\n",
      "fit_word2vec least fit job title 1: Junior MES Engineer| Information Systems\n",
      "fit_word2vec least fit job title 2: Director Of Administration at Excellence Logging\n",
      "fit_word2vec least fit job title 3: Always set them up for Success\n",
      "fit_word2vec least fit job title 4: Undergraduate Research Assistant at Styczynski Lab\n",
      "fit_word2vec least fit job title 5: Admissions Representative at Community medical center long beach\n",
      "\n",
      "fit_fasttext least fit job title 1: Student at Westfield State University\n",
      "fit_fasttext least fit job title 2: Always set them up for Success\n",
      "fit_fasttext least fit job title 3: Director Of Administration at Excellence Logging\n",
      "fit_fasttext least fit job title 4: Junior MES Engineer| Information Systems\n",
      "fit_fasttext least fit job title 5: Business Intelligence and Analytics at Travelers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fit_col in fit_columns:\n",
    "    for i, job_title in enumerate(data.sort_values(fit_col).head().job_title.values):\n",
    "        print(f\"{fit_col} least fit job title {i+1}: {job_title}\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the job titles with the worst fitness scores, each evaluation methods for fitness seems to perform fine - i.e. all those 'worst' job titles do not seem relevant to our keywords. In other words, it would be safe to discard candidates with zero fitness scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = data[ data['has_zero_scores'] != 1 ].drop('has_zero_scores', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are top 20 'best-fit' candidates, after dropping candidates with at least 1 zero fitness scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit_tfidf</th>\n",
       "      <th>fit_keras_tokenizer</th>\n",
       "      <th>fit_glove</th>\n",
       "      <th>fit_word2vec</th>\n",
       "      <th>fit_fasttext</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>4.831050</td>\n",
       "      <td>0.921024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976156</td>\n",
       "      <td>0.933869</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>4.831050</td>\n",
       "      <td>0.921024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976156</td>\n",
       "      <td>0.933869</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>4.765405</td>\n",
       "      <td>0.913385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953443</td>\n",
       "      <td>0.976156</td>\n",
       "      <td>0.922421</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.729689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.851907</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.729689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.851907</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.729689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.851907</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.729689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.851907</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.729689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.851907</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.729689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.851907</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>97</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Kokomo, Indiana Area</td>\n",
       "      <td>71</td>\n",
       "      <td>4.729689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.851907</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>73</td>\n",
       "      <td>Aspiring Human Resources Manager, seeking inte...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>7</td>\n",
       "      <td>4.609975</td>\n",
       "      <td>0.648168</td>\n",
       "      <td>0.979796</td>\n",
       "      <td>0.982011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>4.563690</td>\n",
       "      <td>0.830646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962413</td>\n",
       "      <td>0.857240</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>24</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>4.563690</td>\n",
       "      <td>0.830646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962413</td>\n",
       "      <td>0.857240</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>4.563690</td>\n",
       "      <td>0.830646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962413</td>\n",
       "      <td>0.857240</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>49</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>4.563690</td>\n",
       "      <td>0.830646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962413</td>\n",
       "      <td>0.857240</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>4.563690</td>\n",
       "      <td>0.830646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962413</td>\n",
       "      <td>0.857240</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>Seeking Human Resources Human Resources Inform...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>4.249585</td>\n",
       "      <td>0.736714</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.953667</td>\n",
       "      <td>0.892956</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40</td>\n",
       "      <td>Seeking Human Resources Human Resources Inform...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>4.249585</td>\n",
       "      <td>0.736714</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.953667</td>\n",
       "      <td>0.892956</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>53</td>\n",
       "      <td>Seeking Human Resources Human Resources Inform...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>4.249585</td>\n",
       "      <td>0.736714</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.953667</td>\n",
       "      <td>0.892956</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>62</td>\n",
       "      <td>Seeking Human Resources Human Resources Inform...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>4.249585</td>\n",
       "      <td>0.736714</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.953667</td>\n",
       "      <td>0.892956</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "0   28              Seeking Human Resources Opportunities   \n",
       "1   30              Seeking Human Resources Opportunities   \n",
       "2   99                   Seeking Human Resources Position   \n",
       "3    3              Aspiring Human Resources Professional   \n",
       "4   17              Aspiring Human Resources Professional   \n",
       "5   21              Aspiring Human Resources Professional   \n",
       "6   33              Aspiring Human Resources Professional   \n",
       "7   46              Aspiring Human Resources Professional   \n",
       "8   58              Aspiring Human Resources Professional   \n",
       "9   97              Aspiring Human Resources Professional   \n",
       "10  73  Aspiring Human Resources Manager, seeking inte...   \n",
       "11   6                Aspiring Human Resources Specialist   \n",
       "12  24                Aspiring Human Resources Specialist   \n",
       "13  36                Aspiring Human Resources Specialist   \n",
       "14  49                Aspiring Human Resources Specialist   \n",
       "15  60                Aspiring Human Resources Specialist   \n",
       "16  10  Seeking Human Resources Human Resources Inform...   \n",
       "17  40  Seeking Human Resources Human Resources Inform...   \n",
       "18  53  Seeking Human Resources Human Resources Inform...   \n",
       "19  62  Seeking Human Resources Human Resources Inform...   \n",
       "\n",
       "                               location connection       fit  fit_tfidf  \\\n",
       "0                     Chicago, Illinois        390  4.831050   0.921024   \n",
       "1                     Chicago, Illinois        390  4.831050   0.921024   \n",
       "2                Las Vegas, Nevada Area         48  4.765405   0.913385   \n",
       "3   Raleigh-Durham, North Carolina Area         44  4.729689   1.000000   \n",
       "4   Raleigh-Durham, North Carolina Area         44  4.729689   1.000000   \n",
       "5   Raleigh-Durham, North Carolina Area         44  4.729689   1.000000   \n",
       "6   Raleigh-Durham, North Carolina Area         44  4.729689   1.000000   \n",
       "7   Raleigh-Durham, North Carolina Area         44  4.729689   1.000000   \n",
       "8   Raleigh-Durham, North Carolina Area         44  4.729689   1.000000   \n",
       "9                  Kokomo, Indiana Area         71  4.729689   1.000000   \n",
       "10                  Houston, Texas Area          7  4.609975   0.648168   \n",
       "11           Greater New York City Area          1  4.563690   0.830646   \n",
       "12           Greater New York City Area          1  4.563690   0.830646   \n",
       "13           Greater New York City Area          1  4.563690   0.830646   \n",
       "14           Greater New York City Area          1  4.563690   0.830646   \n",
       "15           Greater New York City Area          1  4.563690   0.830646   \n",
       "16            Greater Philadelphia Area      500+   4.249585   0.736714   \n",
       "17            Greater Philadelphia Area      500+   4.249585   0.736714   \n",
       "18            Greater Philadelphia Area      500+   4.249585   0.736714   \n",
       "19            Greater Philadelphia Area      500+   4.249585   0.736714   \n",
       "\n",
       "    fit_keras_tokenizer  fit_glove  fit_word2vec  fit_fasttext  rank  \n",
       "0              1.000000   1.000000      0.976156      0.933869   1.0  \n",
       "1              1.000000   1.000000      0.976156      0.933869   1.0  \n",
       "2              1.000000   0.953443      0.976156      0.922421   2.0  \n",
       "3              1.000000   0.920193      0.851907      0.957589   3.0  \n",
       "4              1.000000   0.920193      0.851907      0.957589   3.0  \n",
       "5              1.000000   0.920193      0.851907      0.957589   3.0  \n",
       "6              1.000000   0.920193      0.851907      0.957589   3.0  \n",
       "7              1.000000   0.920193      0.851907      0.957589   3.0  \n",
       "8              1.000000   0.920193      0.851907      0.957589   3.0  \n",
       "9              1.000000   0.920193      0.851907      0.957589   3.0  \n",
       "10             0.979796   0.982011      1.000000      1.000000   4.0  \n",
       "11             1.000000   0.962413      0.857240      0.913391   5.0  \n",
       "12             1.000000   0.962413      0.857240      0.913391   5.0  \n",
       "13             1.000000   0.962413      0.857240      0.913391   5.0  \n",
       "14             1.000000   0.962413      0.857240      0.913391   5.0  \n",
       "15             1.000000   0.962413      0.857240      0.913391   5.0  \n",
       "16             0.755929   0.953667      0.892956      0.910319   6.0  \n",
       "17             0.755929   0.953667      0.892956      0.910319   6.0  \n",
       "18             0.755929   0.953667      0.892956      0.910319   6.0  \n",
       "19             0.755929   0.953667      0.892956      0.910319   6.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered['rank'] = data_filtered['fit'].rank(method='dense', ascending=False)\n",
    "data_filtered = data_filtered.sort_values(['rank', 'id', 'connection']).reset_index(drop=True)\n",
    "data_filtered.head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Make initial selections of candidates based on the ranks and train a ranking algorithm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select candidates with top 5 ranks for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered['selected?'] = data_filtered['rank'] <= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = pd.DataFrame(\n",
    "    get_word_vectors(data_filtered, 'job_title', vectorizer='fasttext',\n",
    "                     to_process_text=True, remove_stopwords=True, lemmatize=False, stem=False)\n",
    ")\n",
    "data_selected = pd.concat([data_filtered, training_features], axis=1)\n",
    "X = data_selected[training_features.columns]\n",
    "y = data_selected['selected?']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an XGBoost ranker model using word vectors as training features and the 'selected' column as target the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "random_state = 1\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, test_size, stratify=data_selected['selected?'], random_state=random_state, oversampling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rank of selected candidates based on predictions: 4.6923\n",
      "   selected?  pred_rank\n",
      "7       True        1.0\n",
      "8       True        1.0\n",
      "6       True        1.0\n",
      "5       True        1.0\n",
      "4       True        1.0 \n",
      "\n",
      "Mean rank of selected candidates based on predictions: 3.3333\n",
      "    selected?  pred_rank\n",
      "9        True        1.0\n",
      "3        True        1.0\n",
      "23      False        2.0\n",
      "28      False        3.0\n",
      "25      False        4.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRanker\n",
    "\n",
    "random_state = 1\n",
    "xgb_params = {\n",
    "    'booster': 'gbtree',\n",
    "    'learning_rate': 0.1, # same as eta\n",
    "    'max_depth': 6,\n",
    "    'objective': 'rank:ndcg',\n",
    "    'eval_metric': 'ndcg',\n",
    "    'n_estimators': 100,\n",
    "    'random_state': random_state\n",
    "}\n",
    "xgb_ranker = XGBRanker(**xgb_params)\n",
    "xgb_ranker.fit(X_train, y_train, \n",
    "               group=y_train.value_counts(),\n",
    "               eval_set=[(X_test, y_test)],\n",
    "               eval_group=[y_test.value_counts()]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rank of selected candidates based on predictions: 4.6923\n",
      "   selected?  pred_rank\n",
      "7       True        1.0\n",
      "8       True        1.0\n",
      "6       True        1.0\n",
      "5       True        1.0\n",
      "4       True        1.0 \n",
      "\n",
      "Mean rank of selected candidates based on predictions: 3.3333\n",
      "    selected?  pred_rank\n",
      "9        True        1.0\n",
      "3        True        1.0\n",
      "23      False        2.0\n",
      "28      False        3.0\n",
      "25      False        4.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = get_rank_predictions(X_train, y_train, xgb_ranker, target=\"candidates\")\n",
    "_ = get_rank_predictions(X_test, y_test, xgb_ranker, target=\"candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's ndcg@1: 0.5\tvalid_0's ndcg@3: 0.693426\tvalid_0's ndcg@5: 0.693426\n",
      "[2]\tvalid_0's ndcg@1: 0.5\tvalid_0's ndcg@3: 0.693426\tvalid_0's ndcg@5: 0.693426\n",
      "[3]\tvalid_0's ndcg@1: 0.5\tvalid_0's ndcg@3: 0.693426\tvalid_0's ndcg@5: 0.812025\n",
      "[4]\tvalid_0's ndcg@1: 0.5\tvalid_0's ndcg@3: 0.693426\tvalid_0's ndcg@5: 0.812025\n",
      "[5]\tvalid_0's ndcg@1: 0.5\tvalid_0's ndcg@3: 0.693426\tvalid_0's ndcg@5: 0.812025\n",
      "[6]\tvalid_0's ndcg@1: 0.5\tvalid_0's ndcg@3: 0.693426\tvalid_0's ndcg@5: 0.693426\n",
      "[7]\tvalid_0's ndcg@1: 0.5\tvalid_0's ndcg@3: 0.693426\tvalid_0's ndcg@5: 0.693426\n",
      "[8]\tvalid_0's ndcg@1: 0.5\tvalid_0's ndcg@3: 0.693426\tvalid_0's ndcg@5: 0.693426\n",
      "[9]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[11]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[15]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[16]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[17]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[18]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[19]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[20]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[21]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[22]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[23]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[24]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[25]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[26]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[27]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[28]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[29]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[31]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[32]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[33]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[34]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.925172\n",
      "[35]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[36]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[37]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[38]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.806574\n",
      "[39]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.925172\n",
      "[40]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.925172\n",
      "[41]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[42]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[43]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[44]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[45]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.925172\n",
      "[46]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[47]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[48]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[49]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[50]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[51]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.925172\n",
      "[52]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.925172\n",
      "[53]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.925172\n",
      "[54]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.925172\n",
      "[55]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.925172\n",
      "[56]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[57]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[58]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.925172\n",
      "[59]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[60]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.925172\n",
      "[61]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[62]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[63]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[64]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.925172\n",
      "[65]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[66]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[67]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.95986\tvalid_0's ndcg@5: 0.95986\n",
      "[68]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.95986\tvalid_0's ndcg@5: 0.95986\n",
      "[69]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.925172\n",
      "[70]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.925172\n",
      "[71]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[72]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[73]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[74]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[75]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[76]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[77]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[78]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[79]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[80]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[81]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[82]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[83]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[84]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[85]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[86]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[87]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[88]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[89]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[90]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[91]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[92]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[93]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[94]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[95]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[96]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[97]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[98]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[99]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n",
      "[100]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 0.806574\tvalid_0's ndcg@5: 0.938608\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRanker(label_gain=[0, 1], metric=&#x27;ndcg&#x27;, objective=&#x27;lambdarank&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRanker</label><div class=\"sk-toggleable__content\"><pre>LGBMRanker(label_gain=[0, 1], metric=&#x27;ndcg&#x27;, objective=&#x27;lambdarank&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRanker(label_gain=[0, 1], metric='ndcg', objective='lambdarank')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRanker\n",
    "lgbm_ranker = LGBMRanker(\n",
    "                    objective=\"lambdarank\",\n",
    "                    boosting_type = \"gbdt\",\n",
    "                    n_estimators = 100,\n",
    "                  #   importance_type = \"gain\",\n",
    "                    metric= \"ndcg\",\n",
    "                  #   num_leaves = 10,\n",
    "                  #   learning_rate = 0.05,\n",
    "                  #   max_depth = -1,\n",
    "                    label_gain =[i for i in range(max(y_train.max(), y_test.max()) + 1)])\n",
    "\n",
    "# Training the model\n",
    "lgbm_ranker.fit(\n",
    "      X=X_train,\n",
    "      y=y_train,\n",
    "      group=y_train.value_counts(),\n",
    "      eval_set=[(X_test, y_test)],\n",
    "      eval_group=[y_test.value_counts()],\n",
    "      eval_at=[1,3,5]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rank of selected candidates based on predictions: 1.9231\n",
      "   selected?  pred_rank\n",
      "7       True        1.0\n",
      "8       True        1.0\n",
      "6       True        1.0\n",
      "5       True        1.0\n",
      "4       True        1.0 \n",
      "\n",
      "Mean rank of selected candidates based on predictions: 2.0\n",
      "    selected?  pred_rank\n",
      "9        True        1.0\n",
      "3        True        1.0\n",
      "23      False        2.0\n",
      "25      False        3.0\n",
      "2        True        4.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = get_rank_predictions(X_train, y_train, lgbm_ranker, target=\"candidates\")\n",
    "_ = get_rank_predictions(X_test, y_test, lgbm_ranker, target=\"candidates\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both rankers successfully predicted the top-ranked candidates (i.e. pred_rank == 1.0) as they all were selected candidates.\n",
    "\n",
    "In terms of the mean of predicted ranks for selected candidates, the LGBM ranker performed better at predicting selected candidates. Therefore, the model will be used instead of the XGB ranker for the rest of the project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Star ideal candidates and re-train the ranking model based on the updated ranks/criteria.\n",
    "\n",
    "Since we've built our base ranking model, proceed to starring ideal candidates and re-rank all candidates based on the stars.\n",
    "* Starring one candidate sets this candidate as an ideal candidate for the given role. Then, we expect the list to be re-ranked each time a candidate is starred.\n",
    "* For starred candidates, set the adjusted fit score to the maximum value (i.e. 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>fit_tfidf</th>\n",
       "      <th>fit_keras_tokenizer</th>\n",
       "      <th>fit_glove</th>\n",
       "      <th>fit_word2vec</th>\n",
       "      <th>fit_fasttext</th>\n",
       "      <th>rank</th>\n",
       "      <th>fit_adjusted</th>\n",
       "      <th>rank_adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>4.827587</td>\n",
       "      <td>0.921024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972693</td>\n",
       "      <td>0.933869</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>4.827587</td>\n",
       "      <td>0.921024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972693</td>\n",
       "      <td>0.933869</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.827587</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>4.761943</td>\n",
       "      <td>0.913385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953443</td>\n",
       "      <td>0.972693</td>\n",
       "      <td>0.922421</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.761943</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.739021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.861239</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.739021</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.739021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.861239</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.739021</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.739021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.861239</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.739021</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.739021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.861239</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.739021</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.739021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.861239</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.739021</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>4.739021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.861239</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.739021</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>97</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Kokomo, Indiana Area</td>\n",
       "      <td>71</td>\n",
       "      <td>4.739021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920193</td>\n",
       "      <td>0.861239</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.739021</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>73</td>\n",
       "      <td>Aspiring Human Resources Manager, seeking inte...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>7</td>\n",
       "      <td>4.609975</td>\n",
       "      <td>0.648168</td>\n",
       "      <td>0.979796</td>\n",
       "      <td>0.982011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.609975</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>4.525961</td>\n",
       "      <td>0.830646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962413</td>\n",
       "      <td>0.819512</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.525961</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>24</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>4.525961</td>\n",
       "      <td>0.830646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962413</td>\n",
       "      <td>0.819512</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.525961</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>4.525961</td>\n",
       "      <td>0.830646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962413</td>\n",
       "      <td>0.819512</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.525961</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>49</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>4.525961</td>\n",
       "      <td>0.830646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962413</td>\n",
       "      <td>0.819512</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.525961</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>4.525961</td>\n",
       "      <td>0.830646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962413</td>\n",
       "      <td>0.819512</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.525961</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>Seeking Human Resources Human Resources Inform...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>4.274473</td>\n",
       "      <td>0.736714</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.953667</td>\n",
       "      <td>0.917844</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.274473</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40</td>\n",
       "      <td>Seeking Human Resources Human Resources Inform...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>4.274473</td>\n",
       "      <td>0.736714</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.953667</td>\n",
       "      <td>0.917844</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.274473</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>53</td>\n",
       "      <td>Seeking Human Resources Human Resources Inform...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>4.274473</td>\n",
       "      <td>0.736714</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.953667</td>\n",
       "      <td>0.917844</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.274473</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>62</td>\n",
       "      <td>Seeking Human Resources Human Resources Inform...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>4.274473</td>\n",
       "      <td>0.736714</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>0.953667</td>\n",
       "      <td>0.917844</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.274473</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "1   30              Seeking Human Resources Opportunities   \n",
       "0   28              Seeking Human Resources Opportunities   \n",
       "2   99                   Seeking Human Resources Position   \n",
       "3    3              Aspiring Human Resources Professional   \n",
       "4   17              Aspiring Human Resources Professional   \n",
       "5   21              Aspiring Human Resources Professional   \n",
       "6   33              Aspiring Human Resources Professional   \n",
       "7   46              Aspiring Human Resources Professional   \n",
       "8   58              Aspiring Human Resources Professional   \n",
       "9   97              Aspiring Human Resources Professional   \n",
       "10  73  Aspiring Human Resources Manager, seeking inte...   \n",
       "11   6                Aspiring Human Resources Specialist   \n",
       "12  24                Aspiring Human Resources Specialist   \n",
       "13  36                Aspiring Human Resources Specialist   \n",
       "14  49                Aspiring Human Resources Specialist   \n",
       "15  60                Aspiring Human Resources Specialist   \n",
       "16  10  Seeking Human Resources Human Resources Inform...   \n",
       "17  40  Seeking Human Resources Human Resources Inform...   \n",
       "18  53  Seeking Human Resources Human Resources Inform...   \n",
       "19  62  Seeking Human Resources Human Resources Inform...   \n",
       "\n",
       "                               location connection       fit  fit_tfidf  \\\n",
       "1                     Chicago, Illinois        390  4.827587   0.921024   \n",
       "0                     Chicago, Illinois        390  4.827587   0.921024   \n",
       "2                Las Vegas, Nevada Area         48  4.761943   0.913385   \n",
       "3   Raleigh-Durham, North Carolina Area         44  4.739021   1.000000   \n",
       "4   Raleigh-Durham, North Carolina Area         44  4.739021   1.000000   \n",
       "5   Raleigh-Durham, North Carolina Area         44  4.739021   1.000000   \n",
       "6   Raleigh-Durham, North Carolina Area         44  4.739021   1.000000   \n",
       "7   Raleigh-Durham, North Carolina Area         44  4.739021   1.000000   \n",
       "8   Raleigh-Durham, North Carolina Area         44  4.739021   1.000000   \n",
       "9                  Kokomo, Indiana Area         71  4.739021   1.000000   \n",
       "10                  Houston, Texas Area          7  4.609975   0.648168   \n",
       "11           Greater New York City Area          1  4.525961   0.830646   \n",
       "12           Greater New York City Area          1  4.525961   0.830646   \n",
       "13           Greater New York City Area          1  4.525961   0.830646   \n",
       "14           Greater New York City Area          1  4.525961   0.830646   \n",
       "15           Greater New York City Area          1  4.525961   0.830646   \n",
       "16            Greater Philadelphia Area      500+   4.274473   0.736714   \n",
       "17            Greater Philadelphia Area      500+   4.274473   0.736714   \n",
       "18            Greater Philadelphia Area      500+   4.274473   0.736714   \n",
       "19            Greater Philadelphia Area      500+   4.274473   0.736714   \n",
       "\n",
       "    fit_keras_tokenizer  fit_glove  fit_word2vec  fit_fasttext  rank  \\\n",
       "1              1.000000   1.000000      0.972693      0.933869   1.0   \n",
       "0              1.000000   1.000000      0.972693      0.933869   1.0   \n",
       "2              1.000000   0.953443      0.972693      0.922421   2.0   \n",
       "3              1.000000   0.920193      0.861239      0.957589   3.0   \n",
       "4              1.000000   0.920193      0.861239      0.957589   3.0   \n",
       "5              1.000000   0.920193      0.861239      0.957589   3.0   \n",
       "6              1.000000   0.920193      0.861239      0.957589   3.0   \n",
       "7              1.000000   0.920193      0.861239      0.957589   3.0   \n",
       "8              1.000000   0.920193      0.861239      0.957589   3.0   \n",
       "9              1.000000   0.920193      0.861239      0.957589   3.0   \n",
       "10             0.979796   0.982011      1.000000      1.000000   4.0   \n",
       "11             1.000000   0.962413      0.819512      0.913391   5.0   \n",
       "12             1.000000   0.962413      0.819512      0.913391   5.0   \n",
       "13             1.000000   0.962413      0.819512      0.913391   5.0   \n",
       "14             1.000000   0.962413      0.819512      0.913391   5.0   \n",
       "15             1.000000   0.962413      0.819512      0.913391   5.0   \n",
       "16             0.755929   0.953667      0.917844      0.910319   6.0   \n",
       "17             0.755929   0.953667      0.917844      0.910319   6.0   \n",
       "18             0.755929   0.953667      0.917844      0.910319   6.0   \n",
       "19             0.755929   0.953667      0.917844      0.910319   6.0   \n",
       "\n",
       "    fit_adjusted  rank_adjusted  \n",
       "1       5.000000            1.0  \n",
       "0       4.827587            2.0  \n",
       "2       4.761943            3.0  \n",
       "3       4.739021            4.0  \n",
       "4       4.739021            4.0  \n",
       "5       4.739021            4.0  \n",
       "6       4.739021            4.0  \n",
       "7       4.739021            4.0  \n",
       "8       4.739021            4.0  \n",
       "9       4.739021            4.0  \n",
       "10      4.609975            5.0  \n",
       "11      4.525961            6.0  \n",
       "12      4.525961            6.0  \n",
       "13      4.525961            6.0  \n",
       "14      4.525961            6.0  \n",
       "15      4.525961            6.0  \n",
       "16      4.274473            7.0  \n",
       "17      4.274473            7.0  \n",
       "18      4.274473            7.0  \n",
       "19      4.274473            7.0  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_filtered['fit_adjusted'] = data_filtered['fit']\n",
    "\n",
    "# ideal_candidate = input(\"Enter an ID of an ideal candidate: \")\n",
    "# data_filtered.loc[int(ideal_candidate), 'fit_adjusted'] = 5\n",
    "\n",
    "# data_filtered['rank_adjusted'] = data_filtered['fit_adjusted'].rank(method='dense', ascending=False)\n",
    "# data_filtered.sort_values(['rank_adjusted', 'rank', 'fit_adjusted', 'fit', 'id', 'connection'], inplace=True)\n",
    "# data_filtered.head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- after starring and re-ranking, re-train the model and see how the model performs.\n",
    "- save and load the model for re-training model and making predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4868653bb6f8972e87e4c446ab8a445a15b25dedb8594cc74c480f8152ea86a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
